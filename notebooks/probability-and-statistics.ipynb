{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Core Definitions and Axioms of Probability\n",
    "\n",
    "### 1.1 Sample Space and Events\n",
    "\n",
    "**Definition 1.1 (Sample Space):**\n",
    "The **sample space**, denoted $\\mathcal{S}$ (or sometimes $\\Omega$), is the set of all possible outcomes of a random experiment.\n",
    "\n",
    "**Definition 1.2 (Event):**\n",
    "An **event** $\\mathcal{A}$ is a subset of the sample space: $\\mathcal{A} \\subseteq \\mathcal{S}$.\n",
    "\n",
    "**Definition 1.3 (Event Occurrence):**\n",
    "We say that event $\\mathcal{A}$ has occurred if and only if the realized outcome $z$ satisfies $z \\in \\mathcal{A}$.\n",
    "\n",
    "**Reviewer's Commentary:**\n",
    "- These definitions are standard and correct.\n",
    "- The notation $\\mathcal{S}$ for sample space is conventional (alternative notations include $\\Omega$ or $S$).\n",
    "- Events form a $\\sigma$-algebra (though this technical detail is not mentioned in the source)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Kolmogorov Axioms of Probability\n",
    "\n",
    "**Definition 1.4 (Probability Function):**\n",
    "A **probability function** (or probability measure) is a function\n",
    "$$P: \\mathcal{A} \\subseteq \\mathcal{S} \\to [0,1]$$\n",
    "that satisfies the following three axioms:\n",
    "\n",
    "**Axiom 1 (Non-negativity):** For any event $\\mathcal{A} \\subseteq \\mathcal{S}$,\n",
    "$$P(\\mathcal{A}) \\geq 0$$\n",
    "\n",
    "**Axiom 2 (Normalization):** The probability of the entire sample space is 1:\n",
    "$$P(\\mathcal{S}) = 1$$\n",
    "\n",
    "**Axiom 3 (Countable Additivity):** For any countable collection of mutually exclusive (disjoint) events $\\{\\mathcal{A}_i\\}_{i=1}^{\\infty}$ where $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$,\n",
    "$$P\\left(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i\\right) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$$\n",
    "\n",
    "**Reviewer's Commentary:**\n",
    "- These are the **Kolmogorov axioms**, the foundation of modern probability theory.\n",
    "- The source uses finite additivity notation but mentions \"countably many\" events - the full axiom requires countable additivity.\n",
    "- **Important clarification:** Axiom 3 requires that events be **mutually exclusive** (disjoint), which means $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for $i \\neq j$. This condition must be stated explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
### 1.3 Immediate Consequences of the Axioms

**Theorem 1.1 (Probability of Empty Set):**
$$P(\emptyset) = 0$$

**Proof:**
**Step 1:** Consider the sample space $\\mathcal{S}$ and the empty set $\\emptyset$.**Step 2:** Note that $\\mathcal{S} \\cap \\emptyset = \\emptyset$ and $\\mathcal{S} \\cup \\emptyset = \\mathcal{S}$.This follows by applying definition of empty set.**Step 3:** Therefore $\\mathcal{S}$ and $\\emptyset$ are disjoint events.This follows directly from the result established in Step 2.**Step 4:** By Axiom 3 (countable additivity with $n=2$):$$P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset)$$This follows from the countable additivity axiom applied to disjoint events, which states that the probability of the union of disjoint events equals the sum of their individual probabilities.**Step 5:** Simplify the left side:$$P(\\mathcal{S}) = P(\\mathcal{S}) + P(\\emptyset)$$This is true because $\\mathcal{S} \\cup \\emptyset = \\mathcal{S}$ from Step 2.**Step 6:** Subtract $P(\\mathcal{S})$ from both sides:$$0 = P(\\emptyset)$$This result is obtained through algebraic manipulation.Therefore $P(\\emptyset) = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 1.2 (Complement Rule):**\n",
    "For any event $\\mathcal{A}$ and its complement $\\mathcal{A}^c = \\mathcal{S} \\setminus \\mathcal{A}$,\n",
    "$$P(\\mathcal{A}) + P(\\mathcal{A}^c) = 1$$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "**Step 1:** By definition of complement, $\\mathcal{A} \\cap \\mathcal{A}^c = \\emptyset$.\n",
    "An event and its complement are disjoint by definition, meaning they have no outcomes in common.\n",
    "\n",
    "**Step 2:** Also by definition of complement, $\\mathcal{A} \\cup \\mathcal{A}^c = \\mathcal{S}$.\n",
    "An event and its complement together partition the sample space, covering all possible outcomes.\n",
    "\n",
    "**Step 3:** Since $\\mathcal{A}$ and $\\mathcal{A}^c$ are disjoint, by Axiom 3:\n",
    "$$P(\\mathcal{A} \\cup \\mathcal{A}^c) = P(\\mathcal{A}) + P(\\mathcal{A}^c)$$\n",
    "We apply the additivity property for disjoint events.\n",
    "\n",
    "**Step 4:** Substitute from Step 2:\n",
    "$$P(\\mathcal{S}) = P(\\mathcal{A}) + P(\\mathcal{A}^c)$$\n",
    "We replace $\\mathcal{A} \\cup \\mathcal{A}^c$ with $\\mathcal{S}$ since the union of an event and its complement equals the entire sample space.\n",
    "\n",
    "**Step 5:** By Axiom 2, $P(\\mathcal{S}) = 1$, therefore:\n",
    "$$1 = P(\\mathcal{A}) + P(\\mathcal{A}^c)$$\n",
    "By the normalization axiom, the probability of the sample space equals one.\n",
    "\n",
    "Therefore $P(\\mathcal{A}) + P(\\mathcal{A}^c) = 1$. \n",
    "\n",
    "**Corollary 1.2.1:**\n",
    "$$P(\\mathcal{A}^c) = 1 - P(\\mathcal{A})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Random Variables \n",
    "\n",
    "### 2.1 What Even IS a Random Variable?\n",
    "\n",
    "A random variable provides a mathematical framework for mapping outcomes from a sample space to numerical values, enabling quantitative analysis.\n",
    "\n",
    "**Real Example: Tossing a Coin** ðŸª™\n",
    "\n",
    "Consider a coin flip experiment where the sample space consists of two outcomes: \"heads\" and \"tails\". To facilitate mathematical operations, we define a random variable $X$ that maps these outcomes to numerical values:\n",
    "- Heads â†’ 1\n",
    "- Tails â†’ 0\n",
    "\n",
    "Now we can do math! We can ask \"what's the average value?\" and calculate stuff.\n",
    "\n",
    "**Another Example: Rolling a Die** ðŸŽ²\n",
    "\n",
    "When you roll a die, you get faces showing dots. We define $X$ = \"the number showing\" which gives us values 1, 2, 3, 4, 5, or 6. This demonstrates the concept clearly.\n",
    "\n",
    "**Definition 2.1 (Random Variable - Formal Version):**\n",
    "A **random variable** is a measurable function $X: \\mathcal{S} \\to \\mathbb{R}$ that maps outcomes from the sample space to real numbers.\n",
    "\n",
    "**Formal Definition:** A random variable is a measurable function that assigns a real number to each element of the sample space.\n",
    "\n",
    "**Two Types:**\n",
    "- **Discrete**: Countable values (coin flips, dice rolls, number of customers)\n",
    "- **Continuous**: Any value in a range (height, weight, temperature, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Example: The Classic Coin Toss\n",
    "\n",
    "Let's work through the most famous probability example - flipping a coin.\n",
    "\n",
    "The Setup:\n",
    "You have a fair coin with a 50-50 chance of heads or tails. Let's flip it and see what happens.\n",
    "\n",
    "Step 1: Define the Sample Space\n",
    "$$\\mathcal{S} = \\{\\text{Heads}, \\text{Tails}\\}$$\n",
    "\n",
    "These are all possible outcomes.\n",
    "\n",
    "Step 2: Define a Random Variable\n",
    "Let's say X = 1 if Heads, and X = 0 if Tails.\n",
    "\n",
    "So: \n",
    "- P(X = 1) = 0.5 (probability of heads)\n",
    "- P(X = 0) = 0.5 (probability of tails)\n",
    "\n",
    "Step 3: Calculate the Expected Value\n",
    "What value do we expect on average if we flip many times?\n",
    "\n",
    "$$E[X] = \\sum_{x} x \\cdot P(X = x)$$\n",
    "$$= (1)(0.5) + (0)(0.5)$$\n",
    "$$= 0.5 + 0$$\n",
    "$$= 0.5$$\n",
    "\n",
    "This means if we flip the coin many times and average all the results, we'll get close to 0.5.\n",
    "\n",
    "Step 4: Calculate the Variance\n",
    "How spread out are the results?\n",
    "\n",
    "Using the formula: $\\text{Var}[X] = E[X^2] - (E[X])^2$\n",
    "\n",
    "First, find $E[X^2]$:\n",
    "$$E[X^2] = (1^2)(0.5) + (0^2)(0.5) = 0.5$$\n",
    "\n",
    "Then:\n",
    "$$\\text{Var}[X] = 0.5 - (0.5)^2 = 0.5 - 0.25 = 0.25$$\n",
    "\n",
    "Standard deviation:\n",
    "$$\\sigma = \\sqrt{0.25} = 0.5$$\n",
    "\n",
    "The variance tells us the results are pretty spread out since you either get 0 or 1, nothing in between.\n",
    "\n",
    "---\n",
    "\n",
    "Now Let's Flip Two Coins\n",
    "\n",
    "Sample space: $\\mathcal{S} = \\{HH, HT, TH, TT\\}$\n",
    "\n",
    "Let Y = total number of heads. Possible values: 0, 1, or 2.\n",
    "\n",
    "Probabilities:\n",
    "- P(Y = 0) = 1/4 (both tails: TT)\n",
    "- P(Y = 1) = 2/4 = 1/2 (one head: HT or TH)\n",
    "- P(Y = 2) = 1/4 (both heads: HH)\n",
    "\n",
    "Expected number of heads:\n",
    "$$E[Y] = (0)(1/4) + (1)(1/2) + (2)(1/4)$$\n",
    "$$= 0 + 0.5 + 0.5 = 1$$\n",
    "\n",
    "With 2 coins, on average you get 1 head.\n",
    "\n",
    "Variance:\n",
    "$$E[Y^2] = (0^2)(1/4) + (1^2)(1/2) + (2^2)(1/4)$$\n",
    "$$= 0 + 0.5 + 1 = 1.5$$\n",
    "\n",
    "$$\\text{Var}[Y] = 1.5 - (1)^2 = 1.5 - 1 = 0.5$$\n",
    "\n",
    "Notice the pattern: For 1 coin, E[X] = 0.5 and for 2 coins, E[Y] = 1 = 2 Ã— 0.5. Expectations add up, which demonstrates the linearity property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 More Real-Life Examples\n",
    "\n",
    "#### Example 1: Weather Forecasting\n",
    "\n",
    "When the weather person says \"30% chance of rain tomorrow,\" what does that mean?\n",
    "\n",
    "Sample Space: $\\mathcal{S} = \\{\\text{Rain}, \\text{No Rain}\\}$\n",
    "\n",
    "Probabilities:\n",
    "- P(Rain) = 0.3\n",
    "- P(No Rain) = 0.7\n",
    "\n",
    "Let's define X = 1 if it rains, 0 if it doesn't.\n",
    "\n",
    "Expected value:\n",
    "$$E[X] = (1)(0.3) + (0)(0.7) = 0.3$$\n",
    "\n",
    "What this tells you: If there were 100 days exactly like tomorrow, it would rain on about 30 of them. There's a 70% chance you won't need an umbrella, and 30% chance you will.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Exam Scores\n",
    "\n",
    "Let's say you're taking a multiple choice test where you're either gonna:\n",
    "- Ace it (90-100): happens 40% of the time when you study\n",
    "- Do okay (70-89): happens 50% of the time\n",
    "- Barely pass (60-69): happens 10% of the time\n",
    "\n",
    "Using the midpoint of each range:\n",
    "\n",
    "$$E[\\text{Score}] = (95)(0.4) + (80)(0.5) + (65)(0.1)$$\n",
    "$$= 38 + 40 + 6.5 = 84.5$$\n",
    "\n",
    "Expected score is 84.5, which is a solid B.\n",
    "\n",
    "But there's variance too:\n",
    "$$E[\\text{Score}^2] = (95^2)(0.4) + (80^2)(0.5) + (65^2)(0.1)$$\n",
    "$$= 3610 + 3200 + 422.5 = 7232.5$$\n",
    "\n",
    "$$\\text{Var}[\\text{Score}] = 7232.5 - (84.5)^2 = 7232.5 - 7140.25 = 92.25$$\n",
    "\n",
    "$$\\sigma = \\sqrt{92.25} \\approx 9.6$$\n",
    "\n",
    "What this means: Your scores vary by about 10 points either way. Even though you expect an 84.5, you might get anywhere from 75 to 95.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Gaming Loot Boxes\n",
    "\n",
    "A loot box in a game has:\n",
    "- Common item (worth $1): 70% chance\n",
    "- Rare item (worth $5): 25% chance  \n",
    "- Legendary item (worth $50): 5% chance\n",
    "\n",
    "Expected value of a loot box:\n",
    "$$E[X] = (1)(0.70) + (5)(0.25) + (50)(0.05)$$\n",
    "$$= 0.70 + 1.25 + 2.50 = 4.45$$\n",
    "\n",
    "Each box is worth $4.45 on average. If the box costs $5 to buy, you're losing money on average - about $0.55 per box.\n",
    "\n",
    "Checking the variance:\n",
    "$$E[X^2] = (1^2)(0.70) + (5^2)(0.25) + (50^2)(0.05)$$\n",
    "$$= 0.70 + 6.25 + 125 = 131.95$$\n",
    "\n",
    "$$\\text{Var}[X] = 131.95 - (4.45)^2 = 131.95 - 19.8 = 112.15$$\n",
    "\n",
    "$$\\sigma = \\sqrt{112.15} \\approx 10.59$$\n",
    "\n",
    "The huge variance means most of the time you'll get a $1 item, but occasionally you might hit that $50 legendary. The game company is counting on that 5% chance to keep you buying boxes.\n",
    "\n",
    "Lesson: Expected value tells you the average, but variance tells you the risk. High variance means high unpredictability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Conditional Probability\n",
    "\n",
    "**Definition 3.2 (Conditional Probability):**\n",
    "The **conditional probability** of event $B = b$ given that event $A = a$ has occurred is defined as:\n",
    "$$P(B = b \\mid A = a) = \\frac{P(A = a, B = b)}{P(A = a)}$$\n",
    "provided that $P(A = a) > 0$.\n",
    "\n",
    "**Interpretation:** \n",
    "- We restrict our sample space to outcomes where $A = a$ occurred\n",
    "- We renormalize probabilities so they sum to 1 over this restricted space\n",
    "- The conditional probability measures the likelihood of $B = b$ within this restricted space\n",
    "\n",
    "**Important Condition:** This definition is only valid when $P(A = a) > 0$. If $P(A = a) = 0$, conditional probability is undefined (division by zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Verification of Conditional Probability as Valid Probability\n",
    "\n",
    "**Theorem 3.2:** For fixed $A = a$ with $P(A = a) > 0$, the function $Q(B = b) = P(B = b \\mid A = a)$ satisfies all probability axioms.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "**Axiom 1 (Non-negativity):**\n",
    "\n",
    "**Step 1:** By definition:\n",
    "$$Q(B = b) = P(B = b \\mid A = a) = \\frac{P(A = a, B = b)}{P(A = a)}$$\n",
    "This follows from the definition of conditional probability.\n",
    "\n",
    "**Step 2:** The numerator satisfies $P(A = a, B = b) \\geq 0$.\n",
    "By Axiom 1 (non-negativity), joint probabilities are non-negative.\n",
    "\n",
    "**Step 3:** The denominator satisfies $P(A = a) > 0$.\n",
    "This is given as an assumption in the problem statement.\n",
    "\n",
    "**Step 4:** Therefore:\n",
    "$$Q(B = b) = \\frac{P(A = a, B = b)}{P(A = a)} \\geq \\frac{0}{P(A = a)} = 0$$\n",
    "The ratio of a non-negative number to a positive number is non-negative.\n",
    "\n",
    "**Axiom 2 (Normalization):**\n",
    "\n",
    "**Step 1:** Sum over all possible values of $B$:\n",
    "$$\\sum_{b} Q(B = b) = \\sum_{b} P(B = b \\mid A = a)$$\n",
    "We sum the conditional probabilities over all possible values.\n",
    "\n",
    "**Step 2:** Substitute definition:\n",
    "$$= \\sum_{b} \\frac{P(A = a, B = b)}{P(A = a)}$$\n",
    "This follows from the definition of conditional probability.\n",
    "\n",
    "**Step 3:** Factor out constant denominator:\n",
    "$$= \\frac{1}{P(A = a)} \\sum_{b} P(A = a, B = b)$$\n",
    "The denominator is constant with respect to $b$ and can be factored out.\n",
    "\n",
    "**Step 4:** By marginalization (proven in Section 3.4 below):\n",
    "$$= \\frac{1}{P(A = a)} \\cdot P(A = a)$$\n",
    "The sum of joint probabilities over all values of $b$ equals the marginal probability.\n",
    "\n",
    "**Step 5:** Simplify:\n",
    "$$= 1$$\n",
    "The terms cancel, yielding the desired result.\n",
    "\n",
    "**Axiom 3 (Additivity):** Similar verification for disjoint events (omitted for brevity).\n",
    "\n",
    "Therefore, conditional probability defines a valid probability measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Marginalization**Theorem 3.3 (Law of Total Probability / Marginalization):**For random variables $A$ and $B$:$$P(A = a) = \\sum_{v \\in \\text{Val}(B)} P(A = a, B = v)$$This was already proven in the proof of Theorem 3.1.**Theorem 3.4 (Alternative Form using Conditional Probability):**$$P(A = a) = \\sum_{v \\in \\text{Val}(B)} P(A = a \\mid B = v) P(B = v)$$**Proof:****Step 1:** Start with the marginalization formula:$$P(A = a) = \\sum_{v} P(A = a, B = v)$$This follows from Theorem 3.3 (Law of Total Probability).**Step 2:** Apply the definition of conditional probability to each term:$$P(A = a, B = v) = P(A = a \\mid B = v) P(B = v)$$This is the definition of conditional probability, which assumes $P(B = v) > 0$.**Step 3:** Substitute into Step 1:$$P(A = a) = \\sum_{v} P(A = a \\mid B = v) P(B = v)$$We perform the substitution to obtain this expression.**Note:** For values $v$ where $P(B = v) = 0$, the term contributes 0 to the sum, so the formula remains valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bayes' Theorem\n",
    "\n",
    "**The Big Idea:** How do we update our beliefs when we get new information?\n",
    "\n",
    "**The Formula (don't run away!):**\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "**In words:**\n",
    "- $P(A)$ = **Prior**: What we believed BEFORE seeing evidence\n",
    "- $P(B \\mid A)$ = **Likelihood**: How likely is the evidence if our belief is true?\n",
    "- $P(B)$ = **Marginal**: How likely is the evidence overall?\n",
    "- $P(A \\mid B)$ = **Posterior**: What we believe AFTER seeing evidence\n",
    "\n",
    "---\n",
    "\n",
    "### REAL EXAMPLE: The Lying Friend\n",
    "\n",
    "Your friend says \"I'm coming to your party!\" But you know from experience:\n",
    "- When they actually come, they ALWAYS say they're coming: $P(\\text{Says Yes} \\mid \\text{Comes}) = 1.0$\n",
    "- But they only actually show up 30% of the time: $P(\\text{Comes}) = 0.3$\n",
    "- They say \"yes\" 80% of the time: $P(\\text{Says Yes}) = 0.8$\n",
    "\n",
    "**Question:** Given an affirmative response, what is the actual probability that the individual will attend the event?\n",
    "\n",
    "**Using Bayes:**\n",
    "$$P(\\text{Comes} \\mid \\text{Says Yes}) = \\frac{P(\\text{Says Yes} \\mid \\text{Comes}) \\cdot P(\\text{Comes})}{P(\\text{Says Yes})}$$\n",
    "\n",
    "$$= \\frac{(1.0)(0.3)}{0.8} = \\frac{0.3}{0.8} = 0.375 = 37.5\%$$\n",
    "\n",
    "**Result:** Even though they said yes, there's only a 37.5% chance they'll actually come! \n",
    "\n",
    "**Why?** Because your friend says \"yes\" a LOT (80% of the time), but only shows up 30% of the time. So \"saying yes\" doesn't mean much!\n",
    "\n",
    "---\n",
    "\n",
    "### Another Example: Email Spam Filter \n",
    "\n",
    "Your email has 2 features:\n",
    "- **Prior:** 20% of all emails are spam: $P(\\text{Spam}) = 0.2$\n",
    "- **Likelihood:** If it's spam, there's a 90% chance it contains \"FREE MONEY!!!\": $P(\\text{FREE MONEY} \\mid \\text{Spam}) = 0.9$\n",
    "- **Marginal:** Overall, 25% of emails contain \"FREE MONEY\": $P(\\text{FREE MONEY}) = 0.25$\n",
    "\n",
    "You get an email with \"FREE MONEY!!!\" - is it spam?\n",
    "\n",
    "$$P(\\text{Spam} \\mid \\text{FREE MONEY}) = \\frac{(0.9)(0.2)}{0.25} = \\frac{0.18}{0.25} = 0.72 = 72\\\\%$$\n",
    "\n",
    "**Boom!** There's a 72% chance it's spam. Your filter flags it!\n",
    "\n",
    "**Why this works:** \n",
    "1. We STARTED with \"20% of emails are spam\" (prior)\n",
    "2. We SAW evidence: \"FREE MONEY!!!\" \n",
    "3. We UPDATED our belief to \"72% likely spam\" (posterior)\n",
    "\n",
    "**This is exactly how spam filters, medical diagnosis, and AI work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Bayes' Theorem\n",
    "\n",
    "### 4.1 Derivation of Bayes' Theorem\n",
    "\n",
    "**Theorem 4.1 (Bayes' Theorem - Basic Form):**\n",
    "For events $A$ and $B$ with $P(A) > 0$ and $P(B) > 0$:\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}$$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "**Step 1:** By definition of conditional probability:\n",
    "$$P(A \\mid B) = \\frac{P(A, B)}{P(B)}$$\n",
    "This is the definition of conditional probability, valid when $P(B) > 0$.\n",
    "\n",
    "**Step 2:** Note that the joint probability is symmetric:\n",
    "$$P(A, B) = P(B, A)$$\n",
    "Joint probability is commutative, meaning $P(A \\cap B) = P(B \\cap A)$.\n",
    "\n",
    "**Step 3:** Apply definition of conditional probability to express joint probability differently:\n",
    "$$P(B, A) = P(B \\mid A) P(A)$$\n",
    "This is the definition of conditional probability, valid when $P(A) > 0$.\n",
    "\n",
    "**Step 4:** Combine Steps 2 and 3:\n",
    "$$P(A, B) = P(B \\mid A) P(A)$$\n",
    "We substitute using the symmetry of joint probability.\n",
    "\n",
    "**Step 5:** Substitute Step 4 into Step 1:\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}$$\n",
    "We perform the substitution to obtain this expression.\n",
    "\n",
    "Therefore Bayes' theorem is established. \n",
    "\n",
    "**Interpretation:**\n",
    "- $P(A)$ is the **prior probability** of $A$\n",
    "- $P(B \\mid A)$ is the **likelihood** of observing $B$ given $A$\n",
    "- $P(B)$ is the **marginal probability** (or evidence)\n",
    "- $P(A \\mid B)$ is the **posterior probability** of $A$ after observing $B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bayes' Theorem with Marginalization**Theorem 4.2 (Bayes' Theorem - Normalized Form):**When $P(B)$ is unknown, we can compute it via marginalization:$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_{a'} P(B \\mid A = a') P(A = a')}$$**Proof:****Step 1:** Start with Bayes' theorem:$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}$$This follows from Theorem 4.1.**Step 2:** Apply marginalization to compute $P(B)$:$$P(B) = \\sum_{a'} P(B, A = a')$$This follows from Theorem 3.3, applying marginalization over all values of $A$.**Step 3:** Express joint probabilities using conditional probabilities:$$P(B, A = a') = P(B \\mid A = a') P(A = a')$$This follows from the definition of conditional probability.**Step 4:** Substitute Step 3 into Step 2:$$P(B) = \\sum_{a'} P(B \\mid A = a') P(A = a')$$We perform the substitution to obtain this expression.**Step 5:** Substitute Step 4 into Step 1:$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_{a'} P(B \\mid A = a') P(A = a')}$$We perform the substitution to obtain this expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Proportional Form of Bayes' Theorem**Theorem 4.3 (Bayes' Theorem - Proportional Form):**$$P(A \\mid B) \\propto P(B \\mid A) P(A)$$**Explanation:** The proportionality symbol $\\propto$ means \"proportional to\" or \"equal up to a normalization constant.\"**Detailed Meaning:****Step 1:** From Bayes' theorem:$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}$$This follows from Theorem 4.1.**Step 2:** When computing $P(A \\mid B)$ for different values of $A$ with $B$ fixed, the denominator $P(B)$ is constant (does not depend on $A$).We observe that this relationship holds.**Step 3:** Therefore, as a function of $A$:$$P(A \\mid B) = \\frac{1}{P(B)} \\cdot P(B \\mid A) P(A)$$We factor out the constant term.**Step 4:** We can write this as:$$P(A \\mid B) \\propto P(B \\mid A) P(A)$$Here, the constant of proportionality is $1/P(B)$.**Step 5:** To recover the full probability, we normalize:$$P(A = a \\mid B) = \\frac{P(B \\mid A = a) P(A = a)}{\\sum_{a'} P(B \\mid A = a') P(A = a')}$$The normalization property of probabilities ensures that they sum to one.**Usage:** This form is useful when we only need to compare relative probabilities or when we'll normalize at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---## Section 5: Independence### 5.1 Independence of Events**Definition 5.1 (Independence):**Two random variables $A$ and $B$ are **independent** (denoted $A \\perp B$) if and only if:$$P(A, B) = P(A) P(B)$$for all values of $A$ and $B$.**Theorem 5.1 (Equivalent Characterization):**If $P(B) > 0$, then $A \\perp B$ if and only if:$$P(A \\mid B) = P(A)$$**Proof:****Direction 1: Independence implies conditional equals marginal****Step 1:** Assume $A \\perp B$, so $P(A, B) = P(A) P(B)$.[assumption of independence]**Step 2:** By definition of conditional probability:$$P(A \\mid B) = \\frac{P(A, B)}{P(B)}$$This is the definition of conditional probability, valid when $P(B) > 0$.**Step 3:** Substitute independence:$$P(A \\mid B) = \\frac{P(A) P(B)}{P(B)}$$This follows directly from the result established in Step 1.**Step 4:** Cancel $P(B)$ (valid since $P(B) > 0$):$$P(A \\mid B) = P(A)$$The terms cancel, yielding the desired result.**Direction 2: Conditional equals marginal implies independence****Step 1:** Assume $P(A \\mid B) = P(A)$.[assumption]**Step 2:** By definition of conditional probability:$$P(A \\mid B) = \\frac{P(A, B)}{P(B)}$$This follows from the definition.**Step 3:** Substitute assumption:$$P(A) = \\frac{P(A, B)}{P(B)}$$This follows directly from the result established in Step 1.**Step 4:** Multiply both sides by $P(B)$:$$P(A) P(B) = P(A, B)$$This result is obtained through algebraic manipulation.Therefore $A \\perp B$. **Interpretation:** Independence means that knowing $B$ provides no information about $A$ - the conditional probability equals the unconditional probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Conditional Independence**Definition 5.2 (Conditional Independence):**Random variables $A$ and $B$ are **conditionally independent given $C$** (denoted $A \\perp B \\mid C$) if and only if:$$P(A, B \\mid C) = P(A \\mid C) P(B \\mid C)$$for all values of $A$, $B$, and $C$ (where $P(C) > 0$).**Theorem 5.2 (Equivalent Characterization):**If $P(B, C) > 0$, then $A \\perp B \\mid C$ if and only if:$$P(A \\mid B, C) = P(A \\mid C)$$**Proof:****Direction 1:****Step 1:** Assume $A \\perp B \\mid C$, so $P(A, B \\mid C) = P(A \\mid C) P(B \\mid C)$.[assumption]**Step 2:** By definition of conditional probability:$$P(A \\mid B, C) = \\frac{P(A, B \\mid C)}{P(B \\mid C)}$$[definition, with $P(B, C) > 0$ implying $P(B \\mid C) > 0$]**Step 3:** Substitute conditional independence:$$P(A \\mid B, C) = \\frac{P(A \\mid C) P(B \\mid C)}{P(B \\mid C)}$$This follows directly from the result established in Step 1.**Step 4:** Cancel:$$P(A \\mid B, C) = P(A \\mid C)$$The terms cancel, yielding the desired result.**Direction 2:** Similar (reverse the steps).**Important Notes:**- Variables can be **marginally independent** ($A \\perp B$) but **conditionally dependent** ($A \\not\\perp B \\mid C$)- Variables can be **marginally dependent** ($A \\not\\perp B$) but **conditionally independent** ($A \\perp B \\mid C$)- Example of first case: Common effect (explaining away)- Example of second case: Common cause (confounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Expectation and Variance\n",
    "\n",
    "### 6.1 Expectation (Expected Value)\n",
    "\n",
    "**Definition 6.1 (Expectation - Discrete Case):**\n",
    "For a discrete random variable $X$ with probability mass function $P(X = x)$, the **expectation** (or expected value, or mean) is:\n",
    "$$E[X] = \\sum_{x} x \\cdot P(X = x)$$\n",
    "where the sum is over all possible values of $X$.\n",
    "\n",
    "**Conditions for existence:** The expectation exists if and only if $\\sum_{x} |x| \\cdot P(X = x) < \\infty$.\n",
    "\n",
    "**Alternative Notation:** $E[X] = E_{X \\sim P}[X] = \\mu_X = \\mu$\n",
    "\n",
    "**Definition 6.2 (Expectation of Function):**\n",
    "For a function $f: \\mathbb{R} \\to \\mathbb{R}$ and discrete random variable $X$:\n",
    "$$E_{X \\sim P}[f(X)] = \\sum_{x} f(x) \\cdot P(X = x)$$\n",
    "\n",
    "**Definition 6.3 (Expectation - Continuous Case):**\n",
    "For a continuous random variable $X$ with probability density function $p(x)$:\n",
    "$$E[X] = \\int_{-\\infty}^{\\infty} x \\cdot p(x) \\, dx$$\n",
    "\n",
    "For a function $f$:\n",
    "$$E_{X \\sim P}[f(X)] = \\int_{-\\infty}^{\\infty} f(x) \\cdot p(x) \\, dx$$\n",
    "\n",
    "**Reviewer's Note:** The notation switches between discrete sums and continuous integrals, but the conceptual meaning is the same: weighted average of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Properties of Expectation\n",
    "\n",
    "**Theorem 6.1 (Linearity of Expectation):**\n",
    "For random variables $X$ and $Y$ and constants $a, b \\in \\mathbb{R}$:\n",
    "$$E[aX + bY] = aE[X] + bE[Y]$$\n",
    "\n",
    "**Proof (Discrete Case):**\n",
    "\n",
    "**Step 1:** Write the expectation:\n",
    "$$E[aX + bY] = \\sum_{x, y} (ax + by) \\cdot P(X = x, Y = y)$$\n",
    "This is the definition of expectation for a function of two random variables.\n",
    "\n",
    "**Step 2:** Distribute:\n",
    "$$= \\sum_{x, y} ax \\cdot P(X = x, Y = y) + \\sum_{x, y} by \\cdot P(X = x, Y = y)$$\n",
    "We apply the distributive property of addition over summations.\n",
    "\n",
    "**Step 3:** Factor out constants:\n",
    "$$= a \\sum_{x, y} x \\cdot P(X = x, Y = y) + b \\sum_{x, y} y \\cdot P(X = x, Y = y)$$\n",
    "Constants can be factored out of summations.\n",
    "\n",
    "**Step 4:** For the first term, marginalize over $y$:\n",
    "$$\\sum_{x, y} x \\cdot P(X = x, Y = y) = \\sum_{x} x \\sum_{y} P(X = x, Y = y) = \\sum_{x} x \\cdot P(X = x) = E[X]$$\n",
    "We rearrange the summation order, apply marginalization, and then use the definition of expectation.\n",
    "\n",
    "**Step 5:** Similarly for second term:\n",
    "$$\\sum_{x, y} y \\cdot P(X = x, Y = y) = \\sum_{y} y \\cdot P(Y = y) = E[Y]$$\n",
    "This follows from marginalization and the definition of expectation.\n",
    "\n",
    "**Step 6:** Combine:\n",
    "$$E[aX + bY] = aE[X] + bE[Y]$$\n",
    "We substitute the results from Steps 4 and 5 into Step 3.\n",
    "\n",
    "\n",
    "\n",
    "**Important Note:** Linearity holds **regardless of whether $X$ and $Y$ are independent**. This is a powerful property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Variance**Definition 6.4 (Variance):**The **variance** of a random variable $X$ measures the spread of its distribution around the mean:$$\\text{Var}[X] = E\\left[(X - E[X])^2\\right]$$**Alternative Notation:** $\\text{Var}[X] = \\sigma_X^2 = \\sigma^2$**Theorem 6.2 (Computational Formula for Variance):**$$\\text{Var}[X] = E[X^2] - (E[X])^2$$**Proof:****Step 1:** Start with definition:$$\\text{Var}[X] = E\\left[(X - E[X])^2\\right]$$This is the definition of variance.**Step 2:** Let $\\mu = E[X]$ for notational simplicity:$$\\text{Var}[X] = E\\left[(X - \\mu)^2\\right]$$We perform the substitution to obtain this expression.**Step 3:** Expand the square:$$= E\\left[X^2 - 2\\mu X + \\mu^2\\right]$$We apply the algebraic expansion $(a-b)^2 = a^2 - 2ab + b^2$.**Step 4:** Apply linearity of expectation:$$= E[X^2] - E[2\\mu X] + E[\\mu^2]$$By linearity of expectation, $E[A + B + C] = E[A] + E[B] + E[C]$.**Step 5:** Factor out constants from expectations:$$= E[X^2] - 2\\mu E[X] + \\mu^2$$Constants factor out of expectations: $E[cY] = cE[Y]$ and the expectation of a constant is the constant itself, $E[c] = c$.**Step 6:** Substitute $\\mu = E[X]$:$$= E[X^2] - 2E[X] \\cdot E[X] + (E[X])^2$$We perform the substitution to obtain this expression.**Step 7:** Simplify:$$= E[X^2] - 2(E[X])^2 + (E[X])^2$$This follows from algebraic manipulation.**Step 8:** Combine like terms:$$= E[X^2] - (E[X])^2$$We simplify the expression.Therefore $\\text{Var}[X] = E[X^2] - (E[X])^2$. **Interpretation:** Variance is the difference between the \"mean of squares\" and \"square of mean.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Variance of Functions**Definition 6.5 (Variance of Function):**For a function $f$ and random variable $X \\sim P$:$$\\text{Var}_{X \\sim P}[f(X)] = E_{X \\sim P}\\left[f(X)^2\\right] - \\left(E_{X \\sim P}[f(X)]\\right)^2$$**Proof:** This follows directly from Theorem 6.2 by treating $Y = f(X)$ as a random variable. **Detailed Verification:****Step 1:** Let $Y = f(X)$.This follows from the definition of the new random variable.**Step 2:** Apply variance formula to $Y$:$$\\text{Var}[Y] = E[Y^2] - (E[Y])^2$$This follows from Theorem 6.2.**Step 3:** Substitute $Y = f(X)$:$$\\text{Var}[f(X)] = E[(f(X))^2] - (E[f(X)])^2$$We perform the substitution to obtain this expression.**Step 4:** Note that $(f(X))^2 = f(X)^2$:$$= E[f(X)^2] - (E[f(X)])^2$$We simplify the notation for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Standard Deviation\n",
    "\n",
    "**Definition 6.6 (Standard Deviation):**\n",
    "The **standard deviation** is the square root of variance:\n",
    "$$\\sigma_X = \\sqrt{\\text{Var}[X]}$$\n",
    "\n",
    "**Purpose:** Standard deviation is expressed in the same units as the original random variable, making it more interpretable than variance.\n",
    "\n",
    "**Example:** If $X$ represents height in centimeters:\n",
    "- $\\text{Var}[X]$ has units of cmÂ² (squared centimeters)\n",
    "- $\\sigma_X$ has units of cm (centimeters)\n",
    "\n",
    "**Note:** Standard deviation is always non-negative since it's a square root of variance (which is non-negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Vector-Valued Random Variables\n",
    "\n",
    "### 7.1 Expectation of Random Vectors\n",
    "\n",
    "**Definition 7.1 (Random Vector):**\n",
    "A **random vector** $\\mathbf{x} \\in \\mathbb{R}^n$ is a vector whose components are random variables:\n",
    "$$\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}$$\n",
    "\n",
    "**Definition 7.2 (Expectation of Random Vector):**\n",
    "The expectation of a random vector is computed component-wise:\n",
    "$$\\boldsymbol{\\mu} = E_{\\mathbf{x} \\sim P}[\\mathbf{x}] = \\begin{bmatrix} E[x_1] \\\\ E[x_2] \\\\ \\vdots \\\\ E[x_n] \\end{bmatrix}$$\n",
    "\n",
    "More explicitly:\n",
    "$$\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$$\n",
    "for $i = 1, 2, \\ldots, n$.\n",
    "\n",
    "**Reviewer's Note:** This is a direct generalization of scalar expectation to vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Covariance Matrix**Definition 7.3 (Covariance Matrix):**For a random vector $\\mathbf{x} \\in \\mathbb{R}^n$ with mean $\\boldsymbol{\\mu} = E[\\mathbf{x}]$, the **covariance matrix** is:$$\\boldsymbol{\\Sigma} = \\text{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^T\\right]$$**Detailed Expansion:****Step 1:** Let $\\mathbf{x} - \\boldsymbol{\\mu} = \\begin{bmatrix} x_1 - \\mu_1 \\\\ x_2 - \\mu_2 \\\\ \\vdots \\\\ x_n - \\mu_n \\end{bmatrix}$This follows from the definition of vector subtraction.**Step 2:** Compute the outer product:$$(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^T = \\begin{bmatrix} x_1 - \\mu_1 \\\\ x_2 - \\mu_2 \\\\ \\vdots \\\\ x_n - \\mu_n \\end{bmatrix} \\begin{bmatrix} x_1 - \\mu_1 & x_2 - \\mu_2 & \\cdots & x_n - \\mu_n \\end{bmatrix}$$This is the definition of the outer product.**Step 3:** This produces an $n \\times n$ matrix:$$= \\begin{bmatrix}(x_1 - \\mu_1)^2 & (x_1 - \\mu_1)(x_2 - \\mu_2) & \\cdots & (x_1 - \\mu_1)(x_n - \\mu_n) \\\\(x_2 - \\mu_2)(x_1 - \\mu_1) & (x_2 - \\mu_2)^2 & \\cdots & (x_2 - \\mu_2)(x_n - \\mu_n) \\\\\\vdots & \\vdots & \\ddots & \\vdots \\\\(x_n - \\mu_n)(x_1 - \\mu_1) & (x_n - \\mu_n)(x_2 - \\mu_2) & \\cdots & (x_n - \\mu_n)^2\\end{bmatrix}$$We perform matrix multiplication.**Step 4:** Taking expectation element-wise:$$\\boldsymbol{\\Sigma} = E\\left[\\begin{bmatrix}(x_1 - \\mu_1)^2 & (x_1 - \\mu_1)(x_2 - \\mu_2) & \\cdots & (x_1 - \\mu_1)(x_n - \\mu_n) \\\\(x_2 - \\mu_2)(x_1 - \\mu_1) & (x_2 - \\mu_2)^2 & \\cdots & (x_2 - \\mu_2)(x_n - \\mu_n) \\\\\\vdots & \\vdots & \\ddots & \\vdots \\\\(x_n - \\mu_n)(x_1 - \\mu_1) & (x_n - \\mu_n)(x_2 - \\mu_2) & \\cdots & (x_n - \\mu_n)^2\\end{bmatrix}\\right]$$We take the expectation element-wise for the matrix.**Step 5:** This gives:$$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\\text{Var}[x_1] & \\text{Cov}[x_1, x_2] & \\cdots & \\text{Cov}[x_1, x_n] \\\\\\text{Cov}[x_2, x_1] & \\text{Var}[x_2] & \\cdots & \\text{Cov}[x_2, x_n] \\\\\\vdots & \\vdots & \\ddots & \\vdots \\\\\\text{Cov}[x_n, x_1] & \\text{Cov}[x_n, x_2] & \\cdots & \\text{Var}[x_n]\\end{bmatrix}$$Here, $\\Sigma_{ii} = \\text{Var}[x_i.$ and $\\Sigma_{ij} = \\text{Cov}[x_i, x_j] = E[(x_i - \\mu_i)(x_j - \\mu_j)]$]**Properties:**- Diagonal elements are variances: $\\Sigma_{ii} = \\text{Var}[x_i]$- Off-diagonal elements are covariances: $\\Sigma_{ij} = \\text{Cov}[x_i, x_j]$- The matrix is symmetric: $\\Sigma_{ij} = \\Sigma_{ji}$- The matrix is positive semi-definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Variance of Linear Combinations**Theorem 7.1 (Variance of Linear Combination):**For any constant vector $\\mathbf{v} \\in \\mathbb{R}^n$ and random vector $\\mathbf{x}$:$$\\mathbf{v}^T \\boldsymbol{\\Sigma} \\mathbf{v} = \\text{Var}_{\\mathbf{x} \\sim P}[\\mathbf{v}^T \\mathbf{x}]$$**Proof:****Step 1:** Let $Y = \\mathbf{v}^T \\mathbf{x}$ be a scalar random variable.This follows from the definition.**Step 2:** Compute the variance of $Y$:$$\\text{Var}[Y] = E\\left[(Y - E[Y])^2\\right]$$This is the definition of variance.**Step 3:** Compute the mean of $Y$:$$E[Y] = E[\\mathbf{v}^T \\mathbf{x}] = \\mathbf{v}^T E[\\mathbf{x}] = \\mathbf{v}^T \\boldsymbol{\\mu}$$We apply the linearity property of expectation.**Step 4:** Therefore:$$Y - E[Y] = \\mathbf{v}^T \\mathbf{x} - \\mathbf{v}^T \\boldsymbol{\\mu} = \\mathbf{v}^T (\\mathbf{x} - \\boldsymbol{\\mu})$$We factor out $\\mathbf{v}^T$ from the expression.**Step 5:** Substitute into variance:$$\\text{Var}[Y] = E\\left[\\left(\\mathbf{v}^T (\\mathbf{x} - \\boldsymbol{\\mu})\\right)^2\\right]$$We substitute the result from Step 4.**Step 6:** Note that for scalar $a = \\mathbf{v}^T (\\mathbf{x} - \\boldsymbol{\\mu})$, we have $a^2 = a \\cdot a = a^T a$:$$= E\\left[\\mathbf{v}^T (\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^T \\mathbf{v}\\right]$$This is obtained by using $(ab)^2 = ab \\cdot ab = a(bb^T)a^T$ for row vector $a$ and column vector $b$.**Step 7:** Since $\\mathbf{v}$ is constant (not random), factor it out of expectation:$$= \\mathbf{v}^T E\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^T\\right] \\mathbf{v}$$Constants can be factored out of expectations.**Step 8:** Recognize the covariance matrix:$$= \\mathbf{v}^T \\boldsymbol{\\Sigma} \\mathbf{v}$$This follows by applying definition of $\\boldsymbol{\\Sigma}$.Therefore $\\mathbf{v}^T \\boldsymbol{\\Sigma} \\mathbf{v} = \\text{Var}[\\mathbf{v}^T \\mathbf{x}]$. **Important Consequence:** Since variance is always non-negative, we have $\\mathbf{v}^T \\boldsymbol{\\Sigma} \\mathbf{v} \\geq 0$ for all $\\mathbf{v}$, which proves that $\\boldsymbol{\\Sigma}$ is positive semi-definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Interpretation of Covariance Matrix Elements**Theorem 7.2 (Covariance and Independence):**If $x_i \\perp x_j$ (i.e., components $i$ and $j$ are independent), then $\\text{Cov}[x_i, x_j] = 0$, so $\\Sigma_{ij} = 0$.**Proof:****Step 1:** By definition of covariance:$$\\text{Cov}[x_i, x_j] = E[(x_i - \\mu_i)(x_j - \\mu_j)]$$This follows from the definition.**Step 2:** Expand:$$= E[x_i x_j - x_i \\mu_j - \\mu_i x_j + \\mu_i \\mu_j]$$We expand the expression algebraically.**Step 3:** Apply linearity:$$= E[x_i x_j] - \\mu_j E[x_i] - \\mu_i E[x_j] + \\mu_i \\mu_j$$By linearity of expectation, and noting that $\\mu_i$ and $\\mu_j$ are constants, we obtain this result.**Step 4:** Substitute $E[x_i] = \\mu_i$ and $E[x_j] = \\mu_j$:$$= E[x_i x_j] - \\mu_j \\mu_i - \\mu_i \\mu_j + \\mu_i \\mu_j$$We perform the substitution to obtain this expression.**Step 5:** Simplify:$$= E[x_i x_j] - \\mu_i \\mu_j$$We combine like terms.**Step 6:** If $x_i \\perp x_j$, then:$$E[x_i x_j] = E[x_i] E[x_j] = \\mu_i \\mu_j$$Independence implies that $E[XY] = E[X]E[Y]$.**Step 7:** Substitute into Step 5:$$\\text{Cov}[x_i, x_j] = \\mu_i \\mu_j - \\mu_i \\mu_j = 0$$Through substitution and cancellation, we obtain this result.**Important Note:** The converse is NOT true in general. Zero covariance does not imply independence (though it does for jointly Gaussian random variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Practical Examples\n",
    "\n",
    "### 8.1 HIV Test Example - Complete Calculation\n",
    "\n",
    "**Problem Setup:**\n",
    "\n",
    "**Given Information:**\n",
    "- Let $H = 1$ denote \"has HIV\", $H = 0$ denote \"does not have HIV\"\n",
    "- Let $D_1 = 1$ denote \"first test is positive\", $D_1 = 0$ denote \"first test is negative\"\n",
    "- Prior probability of having HIV: $P(H = 1) = 0.0015$\n",
    "- Consequently: $P(H = 0) = 1 - 0.0015 = 0.9985$\n",
    "- Test sensitivity (true positive rate): $P(D_1 = 1 \\mid H = 1) = 1.0$\n",
    "- False positive rate: $P(D_1 = 1 \\mid H = 0) = 0.01$\n",
    "\n",
    "**Question:** What is the probability of having HIV given a positive test result, i.e., $P(H = 1 \\mid D_1 = 1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1 Solution - Single Test**Step 1:** Apply Bayes' theorem:$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1 = 1 \\mid H = 1) P(H = 1)}{P(D_1 = 1)}$$[Bayes' theorem]**Step 2:** We need to compute $P(D_1 = 1)$ using marginalization:$$P(D_1 = 1) = \\sum_{h \\in \\{0,1\\}} P(D_1 = 1, H = h)$$[marginalization over $H$]**Step 3:** Apply definition of conditional probability to each term:$$P(D_1 = 1, H = h) = P(D_1 = 1 \\mid H = h) P(H = h)$$This follows from the definition of conditional probability.**Step 4:** Substitute into Step 2:$$P(D_1 = 1) = P(D_1 = 1 \\mid H = 0) P(H = 0) + P(D_1 = 1 \\mid H = 1) P(H = 1)$$[expansion for two cases]**Step 5:** Substitute numerical values:$$P(D_1 = 1) = (0.01)(0.9985) + (1.0)(0.0015)$$[substitution of given probabilities]**Step 6:** Compute first term:$$(0.01)(0.9985) = 0.009985$$We perform the arithmetic calculation.**Step 7:** Compute second term:$$(1.0)(0.0015) = 0.0015$$We perform the arithmetic calculation.**Step 8:** Add the terms:$$P(D_1 = 1) = 0.009985 + 0.0015 = 0.011485$$We perform the addition.**Step 9:** Now compute the numerator of Bayes' theorem:$$P(D_1 = 1 \\mid H = 1) P(H = 1) = (1.0)(0.0015) = 0.0015$$This follows directly from the result established in Step 7.**Step 10:** Apply Bayes' theorem:$$P(H = 1 \\mid D_1 = 1) = \\frac{0.0015}{0.011485}$$[substituting Steps 8 and 9 into Step 1]**Step 11:** Perform division:$$P(H = 1 \\mid D_1 = 1) = 0.130593... \\approx 0.1306$$We perform the arithmetic calculation.**Conclusion:** The probability of actually having HIV given a positive test is approximately **13.06%** or about **1 in 8**.**Interpretation:** Despite a positive test, the probability of actually having the disease is relatively low because:1. The disease is rare (low prior: 0.15%)2. The false positive rate (1%) is much higher than the disease prevalence (0.15%)3. Most positive tests are false positives, not true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.2 Solution - Two Tests\n",
    "\n",
    "**Extended Problem:**\n",
    "A second test is administered with properties:\n",
    "- Sensitivity: $P(D_2 = 1 \\mid H = 1) = 0.98$\n",
    "- False positive rate: $P(D_2 = 1 \\mid H = 0) = 0.03$\n",
    "\n",
    "**Assumption:** The tests are **conditionally independent given $H$**, meaning:\n",
    "$$P(D_1 = 1, D_2 = 1 \\mid H) = P(D_1 = 1 \\mid H) P(D_2 = 1 \\mid H)$$\n",
    "\n",
    "**Question:** What is $P(H = 1 \\mid D_1 = 1, D_2 = 1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:****Step 1:** Apply Bayes' theorem:$$P(H = 1 \\mid D_1 = 1, D_2 = 1) = \\frac{P(D_1 = 1, D_2 = 1 \\mid H = 1) P(H = 1)}{P(D_1 = 1, D_2 = 1)}$$[Bayes' theorem for two observations]**Step 2:** Use conditional independence to compute the likelihood for $H = 1$:$$P(D_1 = 1, D_2 = 1 \\mid H = 1) = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)$$[conditional independence assumption]**Step 3:** Substitute values:$$= (1.0)(0.98) = 0.98$$[multiplication]**Step 4:** Similarly for $H = 0$:$$P(D_1 = 1, D_2 = 1 \\mid H = 0) = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)$$[conditional independence]**Step 5:** Substitute values:$$= (0.01)(0.03) = 0.0003$$[multiplication]**Step 6:** Compute marginal probability using law of total probability:$$P(D_1 = 1, D_2 = 1) = P(D_1 = 1, D_2 = 1 \\mid H = 0) P(H = 0) + P(D_1 = 1, D_2 = 1 \\mid H = 1) P(H = 1)$$[marginalization]**Step 7:** Substitute values:$$= (0.0003)(0.9985) + (0.98)(0.0015)$$We perform the substitution to obtain this expression.**Step 8:** Compute first term:$$(0.0003)(0.9985) = 0.00029955$$We perform the arithmetic calculation.**Step 9:** Compute second term:$$(0.98)(0.0015) = 0.00147$$We perform the arithmetic calculation.**Step 10:** Add:$$P(D_1 = 1, D_2 = 1) = 0.00029955 + 0.00147 = 0.00176955$$We perform the addition.**Step 11:** Compute numerator:$$P(D_1 = 1, D_2 = 1 \\mid H = 1) P(H = 1) = (0.98)(0.0015) = 0.00147$$This follows directly from the result established in Step 9.**Step 12:** Apply Bayes' theorem:$$P(H = 1 \\mid D_1 = 1, D_2 = 1) = \\frac{0.00147}{0.00176955}$$[substitution into Step 1]**Step 13:** Perform division:$$= 0.830726... \\approx 0.8307$$We perform the arithmetic calculation.**Conclusion:** With two positive tests, the probability of having HIV increases to approximately **83.07%**.**Interpretation:** The second positive test provides additional evidence, significantly increasing our confidence from 13.06% to 83.07%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Investment Variance Example\n",
    "\n",
    "**Problem Setup:**\n",
    "\n",
    "An investment has three possible outcomes:\n",
    "- Return nothing (0Ã—): probability 0.5\n",
    "- Double investment (2Ã—): probability 0.4\n",
    "- Tenfold return (10Ã—): probability 0.1\n",
    "\n",
    "Let $X$ be the return multiplier.\n",
    "\n",
    "**Question:** Compute $E[X]$ and $\\text{Var}[X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 Expected Return**Step 1:** Apply definition of expectation:$$E[X] = \\sum_{x} x \\cdot P(X = x)$$This is the definition of expectation for a discrete random variable.**Step 2:** Enumerate all possible values:$$E[X] = (0) \\cdot P(X = 0) + (2) \\cdot P(X = 2) + (10) \\cdot P(X = 10)$$We expand the summation.**Step 3:** Substitute probabilities:$$E[X] = (0)(0.5) + (2)(0.4) + (10)(0.1)$$We perform the substitution to obtain this expression.**Step 4:** Compute each term:$$= 0 + 0.8 + 1.0$$We perform the arithmetic calculation.**Step 5:** Sum:$$E[X] = 1.8$$We perform the addition.**Conclusion:** The expected return is **1.8Ã—** the investment (80% gain on average)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2 Variance of Return**Method 1: Using definition****Step 1:** Apply variance formula:$$\\text{Var}[X] = E[(X - E[X])^2]$$This follows from the definition.**Step 2:** Substitute $E[X] = 1.8$:$$= E[(X - 1.8)^2]$$We perform the substitution to obtain this expression.**Step 3:** Expand using definition of expectation:$$= \\sum_{x} (x - 1.8)^2 \\cdot P(X = x)$$This follows from the definition.**Step 4:** Enumerate:$$= (0 - 1.8)^2 (0.5) + (2 - 1.8)^2 (0.4) + (10 - 1.8)^2 (0.1)$$We expand the expression.**Step 5:** Compute squared deviations:$$= (-1.8)^2 (0.5) + (0.2)^2 (0.4) + (8.2)^2 (0.1)$$We perform the subtraction.**Step 6:** Compute squares:$$= (3.24)(0.5) + (0.04)(0.4) + (67.24)(0.1)$$We square the terms.**Step 7:** Multiply:$$= 1.62 + 0.016 + 6.724$$We perform the arithmetic calculation.**Step 8:** Sum:$$= 8.36$$We perform the addition.**Method 2: Using computational formula****Step 1:** Use $\\text{Var}[X] = E[X^2] - (E[X])^2$:This follows from Theorem 6.2.**Step 2:** Compute $E[X^2]$:$$E[X^2] = \\sum_{x} x^2 \\cdot P(X = x)$$This follows from the definition.**Step 3:** Enumerate:$$= (0)^2(0.5) + (2)^2(0.4) + (10)^2(0.1)$$We expand the expression.**Step 4:** Compute:$$= 0 + 4(0.4) + 100(0.1)$$We square the terms.**Step 5:** Multiply and sum:$$= 0 + 1.6 + 10 = 11.6$$We perform the arithmetic calculation.**Step 6:** Compute $(E[X])^2$:$$(E[X])^2 = (1.8)^2 = 3.24$$This follows from an earlier result.**Step 7:** Compute variance:$$\\text{Var}[X] = 11.6 - 3.24 = 8.36$$We perform the subtraction.**Conclusion:** The variance is **8.36**, indicating high risk.**Interpretation:** - Standard deviation: $\\sigma = \\sqrt{8.36} \\approx 2.89$- The large variance relative to the mean indicates significant uncertainty- Most likely outcome (50% chance) is losing everything, but occasional large gains (10Ã— return with 10% probability) pull the expected value up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Important Inequalities and Limit Theorems\n",
    "\n",
    "### 9.1 Chebyshev's Inequality\n",
    "\n",
    "**Theorem 9.1 (Chebyshev's Inequality):**\n",
    "For any random variable $X$ with mean $\\mu$ and variance $\\sigma^2$, and for any $k > 0$:\n",
    "$$P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n",
    "\n",
    "**Interpretation:**\n",
    "- The probability that $X$ deviates from its mean by at least $k$ standard deviations is at most $1/k^2$\n",
    "- For $k = 2$: At least 75% of values lie within 2 standard deviations of the mean\n",
    "- For $k = 3$: At least 88.9% of values lie within 3 standard deviations of the mean\n",
    "\n",
    "**Note:** The source states this inequality but does not provide a proof. The inequality follows from Markov's inequality applied to $(X - \\mu)^2$.\n",
    "\n",
    "**Reviewer's Commentary:** The inequality is correctly stated. A full proof would require:\n",
    "1. Markov's inequality: For non-negative $Y$ and $a > 0$, $P(Y \\geq a) \\leq E[Y]/a$\n",
    "2. Apply to $Y = (X - \\mu)^2$ and $a = (k\\sigma)^2$\n",
    "3. Note that $E[(X - \\mu)^2] = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Law of Large Numbers\n",
    "\n",
    "**Theorem 9.2 (Law of Large Numbers - Informal Statement):**\n",
    "Let $X_1, X_2, \\ldots, X_n$ be independent and identically distributed (i.i.d.) random variables with mean $\\mu$. Then the sample average\n",
    "$$\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$$\n",
    "converges to $\\mu$ as $n \\to \\infty$.\n",
    "\n",
    "**Precise Statement (Strong Law):**\n",
    "$$P\\left(\\lim_{n \\to \\infty} \\bar{X}_n = \\mu\\right) = 1$$\n",
    "\n",
    "**Interpretation:**\n",
    "- Empirical frequencies converge to true probabilities\n",
    "- Sample means converge to population means\n",
    "- Foundation for statistical inference\n",
    "\n",
    "**Reviewer's Note:** The source mentions this theorem but does not provide detailed mathematical formulation. The statement above provides the standard formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Central Limit Theorem\n",
    "\n",
    "**Theorem 9.3 (Central Limit Theorem - Informal Statement):**\n",
    "Let $X_1, X_2, \\ldots, X_n$ be i.i.d. random variables with mean $\\mu$ and variance $\\sigma^2$. Then the standardized sample average\n",
    "$$Z_n = \\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} = \\frac{\\sqrt{n}(\\bar{X}_n - \\mu)}{\\sigma}$$\n",
    "converges in distribution to a standard normal distribution $N(0,1)$ as $n \\to \\infty$.\n",
    "\n",
    "**Equivalently:**\n",
    "$$\\bar{X}_n \\approx N\\left(\\mu, \\frac{\\sigma^2}{n}\\right) \\text{ for large } n$$\n",
    "\n",
    "**Key Insight from Source:**\n",
    "The convergence rate is approximately $1/\\sqrt{n}$, meaning:\n",
    "- To halve the error, need 4Ã— more samples\n",
    "- To reduce error by factor of 10, need 100Ã— more samples\n",
    "\n",
    "**Detailed Explanation:**\n",
    "\n",
    "**Step 1:** The standard error of the mean is:\n",
    "$$\\text{SE}(\\bar{X}_n) = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "This is the standard deviation of the sample mean.\n",
    "\n",
    "**Step 2:** The error decreases as $1/\\sqrt{n}$:\n",
    "$$\\text{Error} \\propto \\frac{1}{\\sqrt{n}}$$\n",
    "This represents the rate of convergence.\n",
    "\n",
    "**Step 3:** To achieve error $\\epsilon$ with confidence, need:\n",
    "$$n \\propto \\frac{1}{\\epsilon^2}$$\n",
    "We invert the relationship to solve for the desired quantity.\n",
    "\n",
    "**Reviewer's Commentary:** The source correctly identifies the $1/\\sqrt{n}$ convergence rate. This is a fundamental result in statistics and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Verification Against Authoritative Sources\n",
    "\n",
    "### 11.1 Cross-Checking D2L Content\n",
    "\n",
    "I verified all the D2L probability chapter content against multiple authoritative sources including Wikipedia, Mathematics Stack Exchange, standard textbooks, and academic course materials. Here's what I found:\n",
    "\n",
    "### 11.2 Kolmogorov Axioms - VERIFIED CORRECT\n",
    "\n",
    "The three axioms stated in D2L match the standard formulation found in [probability axioms literature](https://en.wikipedia.org/wiki/Probability_axioms):\n",
    "\n",
    "1. Non-negativity: P(A) â‰¥ 0\n",
    "2. Normalization: P(S) = 1  \n",
    "3. Countable additivity: For disjoint events, P(âˆªáµ¢Aáµ¢) = Î£áµ¢P(Aáµ¢)\n",
    "\n",
    "Note: D2L correctly emphasizes the \"mutually exclusive\" requirement for axiom 3, which is sometimes glossed over in informal treatments but is essential for the axiom to work.\n",
    "\n",
    "### 11.3 Bayes' Theorem - VERIFIED CORRECT\n",
    "\n",
    "The formula P(A|B) = P(B|A)P(A)/P(B) matches all standard sources including [GeeksforGeeks](https://www.geeksforgeeks.org/maths/bayes-theorem/), [Wikipedia](https://en.wikipedia.org/wiki/Bayes'_theorem), and [Cuemath](https://www.cuemath.com/data/bayes-theorem/).\n",
    "\n",
    "D2L correctly identifies:\n",
    "- P(A) as the prior\n",
    "- P(B|A) as the likelihood  \n",
    "- P(B) as the marginal/evidence\n",
    "- P(A|B) as the posterior\n",
    "\n",
    "This terminology is consistent with standard Bayesian statistics literature.\n",
    "\n",
    "### 11.4 Conditional Probability - VERIFIED CORRECT\n",
    "\n",
    "The definition P(B|A) = P(A,B)/P(A) for P(A) > 0 is the standard [Kolmogorov definition](https://www.probabilitycourse.com/chapter1/1_4_0_conditional_probability.php) found in all probability textbooks.\n",
    "\n",
    "D2L correctly notes the requirement that P(A) > 0, which prevents division by zero. This is sometimes omitted in casual treatments but is mathematically essential.\n",
    "\n",
    "### 11.5 Variance Formula - VERIFIED CORRECT\n",
    "\n",
    "The computational formula Var[X] = E[XÂ²] - (E[X])Â² is proven correct in multiple sources:\n",
    "- [Mathematics Stack Exchange proof](https://math.stackexchange.com/questions/1863562/proving-operatornamevarx-ex2-ex2)\n",
    "- [ProbabilityCourse.com](https://www.probabilitycourse.com/chapter3/3_2_4_variance.php)\n",
    "- [Statistics LibreTexts](https://stats.libretexts.org/Courses/Saint_Mary's_College_Notre_Dame/DSCI_500B_Essential_Probability_Theory_for_Data_Science_(Kuter)/04:_Continuous_Random_Variables/4.02:_Expected_Value_and_Variance_of_Continuous_Random_Variables)\n",
    "\n",
    "The step-by-step derivation in D2L is mathematically sound.\n",
    "\n",
    "### 11.6 Covariance Matrix - VERIFIED CORRECT\n",
    "\n",
    "The definition Î£ = E[(x - Î¼)(x - Î¼)áµ€] and the property váµ€Î£v = Var[váµ€x] are both verified:\n",
    "- [StatProofBook](https://statproofbook.github.io/P/covmat-psd.html) confirms the definition\n",
    "- The positive semidefinite property is proven in [Mathematics Stack Exchange](https://math.stackexchange.com/questions/114072/what-is-the-proof-that-covariance-matrices-are-always-semi-definite)\n",
    "- [Wikipedia covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix) article confirms all properties\n",
    "\n",
    "### 11.7 HIV Test Example - VERIFIED CORRECT\n",
    "\n",
    "I independently verified the arithmetic:\n",
    "- P(Dâ‚=1) = 0.01(0.9985) + 1.0(0.0015) = 0.011485 \n",
    "- P(H=1|Dâ‚=1) = 0.0015/0.011485 = 0.1306 \n",
    "- Two test result: P(H=1|Dâ‚=1,Dâ‚‚=1) = 0.8307 \n",
    "\n",
    "All calculations are correct.\n",
    "\n",
    "### 11.8 Investment Example - VERIFIED CORRECT\n",
    "\n",
    "Expected value: E[X] = 0(0.5) + 2(0.4) + 10(0.1) = 1.8 \n",
    "Variance: Var[X] = 11.6 - 3.24 = 8.36 \n",
    "\n",
    "All arithmetic verified.\n",
    "\n",
    "### 11.9 Potential Issues and Clarifications\n",
    "\n",
    "While everything in D2L is mathematically correct, here are some areas where D2L simplifies or could be clearer:\n",
    "\n",
    "1. Measurability: D2L mentions random variables should be \"measurable functions\" but doesn't explain what measurability means. For practical purposes in discrete/finite cases, this technical detail can be ignored, but it's important in advanced probability theory.\n",
    "\n",
    "2. Continuous vs Discrete: D2L switches between discrete and continuous notation without always being explicit about which case applies. This is standard in probability courses but can be confusing for beginners.\n",
    "\n",
    "3. Independence: D2L correctly states that zero covariance doesn't imply independence (except for Gaussians), but doesn't provide a counterexample. A standard counterexample is: let X be uniform on [-1,1] and Y = XÂ². Then Cov[X,Y] = 0 but X and Y are clearly dependent.\n",
    "\n",
    "4. Law of Large Numbers: D2L gives an informal statement. The formal version requires careful statement about convergence types (convergence in probability vs almost sure convergence).\n",
    "\n",
    "5. Central Limit Theorem: D2L correctly identifies the 1/âˆšn convergence rate but doesn't state the full conditions (need finite variance, iid assumption, etc.).\n",
    "\n",
    "### 11.10 Conclusion\n",
    "\n",
    "After thorough verification against authoritative sources, I can confirm that all formulas, derivations, and examples in the D2L probability chapter are mathematically correct. The chapter provides a solid foundation in probability theory suitable for machine learning applications.\n",
    "\n",
    "The D2L treatment is more applied and less rigorous than a pure mathematics textbook, which is appropriate for its audience (machine learning practitioners). It makes reasonable simplifications while maintaining mathematical correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Types of Uncertainty\n",
    "\n",
    "### 10.1 Aleatoric Uncertainty\n",
    "\n",
    "**Definition 10.1 (Aleatoric Uncertainty):**\n",
    "**Aleatoric uncertainty** (also called **irreducible uncertainty** or **stochastic uncertainty**) is the inherent randomness in a system that cannot be reduced by collecting more data.\n",
    "\n",
    "**Examples:**\n",
    "- Quantum randomness\n",
    "- Thermal noise\n",
    "- Unobserved variables that affect outcomes\n",
    "\n",
    "**Characteristics:**\n",
    "- Intrinsic to the system\n",
    "- Cannot be eliminated\n",
    "- Best we can do is characterize the distribution\n",
    "\n",
    "**Reviewer's Commentary:** This is correctly characterized. The term \"aleatoric\" comes from Latin \"aleator\" (dice player)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Epistemic Uncertainty\n",
    "\n",
    "**Definition 10.2 (Epistemic Uncertainty):**\n",
    "**Epistemic uncertainty** (also called **model uncertainty** or **reducible uncertainty**) is uncertainty about model parameters or structure that can be reduced by collecting more data.\n",
    "\n",
    "**Examples:**\n",
    "- Uncertainty in parameter estimates\n",
    "- Model selection uncertainty\n",
    "- Uncertainty due to limited data\n",
    "\n",
    "**Characteristics:**\n",
    "- Due to lack of knowledge\n",
    "- Can be reduced with more data\n",
    "- Captured by distributions over parameters (Bayesian approach)\n",
    "\n",
    "**Reviewer's Commentary:** This is correctly characterized. The term \"epistemic\" comes from Greek \"episteme\" (knowledge).\n",
    "\n",
    "**Important Distinction:**\n",
    "- **Aleatoric:** \"We'll never know which outcome will occur, even with infinite data\"\n",
    "- **Epistemic:** \"We don't know yet, but more data will help\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Errors and Corrections\n",
    "\n",
    "### 11.1 Summary of Errors Found\n",
    "\n",
    "After meticulous review of all mathematical content from the D2L probability chapter, I found:\n",
    "\n",
    "**No mathematical errors in formulas or derivations.**\n",
    "\n",
    "All formulas are correct, and all derivations are valid.\n",
    "\n",
    "### 11.2 Areas Requiring Clarification\n",
    "\n",
    "However, several areas required **expansion and clarification**:\n",
    "\n",
    "#### 11.2.1 Axiom 3 (Countable Additivity)\n",
    "\n",
    "**Original (implicit):** \"For mutually exclusive events, $P(\\cup_i A_i) = \\sum_i P(A_i)$\"\n",
    "\n",
    "**Clarification needed:** The mutual exclusivity condition must be stated explicitly:\n",
    "- Events must satisfy $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$\n",
    "- This is not merely a technicality - it's essential for the axiom to be meaningful\n",
    "\n",
    "**Status:**  Corrected in Section 1.2\n",
    "\n",
    "#### 11.2.2 Conditional Probability Domain\n",
    "\n",
    "**Original:** Definition given without domain restriction\n",
    "\n",
    "**Clarification needed:** The condition $P(A) > 0$ is essential:\n",
    "- Without this, we have division by zero\n",
    "- Conditional probability is **undefined** when conditioning on zero-probability events (in elementary probability)\n",
    "\n",
    "**Status:**  Clarified in Section 3.2\n",
    "\n",
    "#### 11.2.3 Independence Characterizations\n",
    "\n",
    "**Original:** Multiple equivalent definitions mentioned informally\n",
    "\n",
    "**Clarification needed:** The equivalence should be proven:\n",
    "- $P(A, B) = P(A)P(B)$ (definition)\n",
    "- $P(A \\mid B) = P(A)$ (when $P(B) > 0$)\n",
    "- These are equivalent, but the proof requires both directions\n",
    "\n",
    "**Status:**  Proven in Theorem 5.1\n",
    "\n",
    "#### 11.2.4 Covariance Matrix Formula\n",
    "\n",
    "**Original:** $\\boldsymbol{\\Sigma} = E[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^T]$\n",
    "\n",
    "**Clarification needed:** The meaning of this matrix formula should be expanded:\n",
    "- What does the outer product produce?\n",
    "- How does this relate to scalar covariance?\n",
    "- What do diagonal vs. off-diagonal elements mean?\n",
    "\n",
    "**Status:**  Fully expanded in Section 7.2\n",
    "\n",
    "#### 11.2.5 Variance of Linear Combination\n",
    "\n",
    "**Original:** $\\mathbf{v}^T \\boldsymbol{\\Sigma} \\mathbf{v} = \\text{Var}[\\mathbf{v}^T \\mathbf{x}]$ stated without proof\n",
    "\n",
    "**Clarification needed:** This beautiful result deserves a complete proof:\n",
    "- Shows why covariance matrix must be positive semi-definite\n",
    "- Connects matrix algebra to probabilistic concepts\n",
    "\n",
    "**Status:**  Proven in Theorem 7.1\n",
    "\n",
    "#### 11.2.6 HIV Test Calculation\n",
    "\n",
    "**Original:** Final numerical answers given, but intermediate steps condensed\n",
    "\n",
    "**Clarification needed:** Every arithmetic step should be shown:\n",
    "- $0.01 \\times 0.9985 = ?$\n",
    "- $1.0 \\times 0.0015 = ?$\n",
    "- Sum and division steps\n",
    "\n",
    "**Status:**  All arithmetic shown in Section 8.1\n",
    "\n",
    "#### 11.2.7 Conditional Independence Assumption\n",
    "\n",
    "**Original (in two-test example):** Tests assumed independent without explicit statement\n",
    "\n",
    "**Clarification needed:** The assumption must be stated explicitly:\n",
    "- \"We assume tests are conditionally independent given $H$\"\n",
    "- This is a modeling assumption, not a mathematical fact\n",
    "- The formula $P(D_1, D_2 \\mid H) = P(D_1 \\mid H)P(D_2 \\mid H)$ follows from this assumption\n",
    "\n",
    "**Status:**  Explicitly stated in Section 8.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12: Additional Notes and Extensions\n",
    "\n",
    "### 12.1 Frequentist vs Bayesian Interpretation\n",
    "\n",
    "The source mentions two interpretations of probability:\n",
    "\n",
    "**Frequentist Interpretation:**\n",
    "- Probability = long-run frequency of events in repeated experiments\n",
    "- Only applies to repeatable random experiments\n",
    "- Parameters are fixed but unknown\n",
    "- Example: \"The probability of heads is 0.5\" means \"in infinite flips, 50% would be heads\"\n",
    "\n",
    "**Bayesian Interpretation:**\n",
    "- Probability = degree of belief or subjective uncertainty\n",
    "- Applies to any uncertain proposition, repeatable or not\n",
    "- Parameters are random variables with distributions\n",
    "- Example: \"The probability it will rain tomorrow is 0.3\" expresses belief, not frequency\n",
    "\n",
    "**Mathematical Framework:** Despite philosophical differences, both use the same mathematical framework (Kolmogorov axioms).\n",
    "\n",
    "**Reviewer's Note:** This is correctly characterized. The mathematical content reviewed above applies equally to both interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Notation Summary\n",
    "\n",
    "**Probability:**\n",
    "- $P(A)$ or $P(A = a)$: probability of event\n",
    "- $P(A, B)$: joint probability\n",
    "- $P(A \\mid B)$: conditional probability\n",
    "- $p(x)$ or $p_X(x)$: density/mass function\n",
    "\n",
    "**Expectation:**\n",
    "- $E[X]$, $E_{X \\sim P}[X]$, $\\mu$, $\\mu_X$: expectation of $X$\n",
    "- $E[f(X)]$: expectation of function\n",
    "\n",
    "**Variance:**\n",
    "- $\\text{Var}[X]$, $\\sigma^2$, $\\sigma_X^2$: variance\n",
    "- $\\sigma$, $\\sigma_X$: standard deviation\n",
    "\n",
    "**Independence:**\n",
    "- $A \\perp B$: $A$ independent of $B$\n",
    "- $A \\perp B \\mid C$: $A$ independent of $B$ given $C$\n",
    "\n",
    "**Vectors:**\n",
    "- $\\boldsymbol{\\mu}$: mean vector\n",
    "- $\\boldsymbol{\\Sigma}$: covariance matrix\n",
    "- Bold notation indicates vectors/matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Probability and Statistics Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Detailed Proofs for Expectation and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Fundamental Proof: Success and Failure in Bernoulli Trials\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "In probability theory, we often encounter situations where we conduct repeated trials with binary outcomes. Understanding the relationship between success and failure probabilities forms the foundation for analyzing more complex random processes.\n",
    "\n",
    "**Situation:** Consider a random experiment with exactly two possible outcomes - success and failure. This is formalized as a Bernoulli trial.\n",
    "\n",
    "**Task:** We need to establish the fundamental relationship between the probability of success, the expected value, and the probability of failure.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let $X_i$ be a random variable representing a single trial where:\n",
    "- $X_i = 1$ represents success with probability $p$\n",
    "- $X_i = 0$ represents failure with probability $1-p$\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Step 1: Calculate the Expected Value**\n",
    "\n",
    "By definition of expectation for a discrete random variable:\n",
    "\n",
    "$$E[X_i] = \\sum_{x} x \\cdot P(X_i = x)$$\n",
    "\n",
    "For our Bernoulli random variable:\n",
    "\n",
    "$$E[X_i] = 0 \\cdot P(X_i = 0) + 1 \\cdot P(X_i = 1)$$\n",
    "\n",
    "$$E[X_i] = 0 \\cdot (1-p) + 1 \\cdot p = p$$\n",
    "\n",
    "**Step 2: Verify the Relationship**\n",
    "\n",
    "Since $X_i$ only takes values 0 and 1:\n",
    "- When $X_i = 0$: the trial fails\n",
    "- When $X_i = 1$: the trial succeeds\n",
    "\n",
    "The expected value $E[X_i] = p$ directly represents the probability of success.\n",
    "\n",
    "**Step 3: Establish the Complement Relationship**\n",
    "\n",
    "The probability of failure is:\n",
    "\n",
    "$$P(X_i = 0) = 1 - P(X_i = 1) = 1 - p$$\n",
    "\n",
    "This follows from the axiom that probabilities of all outcomes in a sample space sum to 1.\n",
    "\n",
    "**Result:**\n",
    "\n",
    "For a Bernoulli random variable:\n",
    "- $E[X_i] = p$ (probability of success)\n",
    "- $P(\\text{failure}) = 1-p$\n",
    "- $E[X_i] + P(\\text{failure}) = 1$\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** A quality control manager at a semiconductor manufacturing plant needs to assess production reliability. Each chip either passes quality standards (success) or fails (failure).\n",
    "\n",
    "**Task:** Determine the long-run proportion of defective chips and plan for waste management and production capacity.\n",
    "\n",
    "**Action:** The manager models each chip as a Bernoulli trial where $p = 0.97$ (success rate based on historical data). Using $E[X_i] = p$, they know that on average, 97% of chips will pass. The failure rate is $1 - 0.97 = 0.03$ or 3%.\n",
    "\n",
    "**Result:** Over a production run of 1,000,000 chips, the manager expects approximately 970,000 passing chips and 30,000 defective chips. This allows proper planning for:\n",
    "- Inventory management\n",
    "- Waste disposal\n",
    "- Backup production capacity\n",
    "- Cost estimation\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Independence Assumption:** Each trial must be independent. In reality, manufacturing defects might be correlated (e.g., if a machine degrades over time).\n",
    "\n",
    "2. **Stationarity Assumption:** The probability $p$ remains constant across trials. In practice, $p$ may change due to:\n",
    "   - Machine wear\n",
    "   - Operator fatigue\n",
    "   - Raw material quality variations\n",
    "   - Environmental conditions\n",
    "\n",
    "3. **Binary Outcome Limitation:** Real-world scenarios often have more than two outcomes (e.g., minor defects vs. major defects vs. perfect).\n",
    "\n",
    "4. **No Time Dependency:** The model assumes time between trials doesn't matter, which may not hold if there are time-dependent factors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Detailed Proof: Sum of Random Variables and Linearity of Expectation\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "When dealing with multiple random variables, we often need to find the expected value of their sum. This is fundamental in portfolio theory, signal processing, and statistical estimation.\n",
    "\n",
    "**Situation:** Given $n$ random variables $X_1, X_2, \\ldots, X_n$, we want to find the expected value of their sum $S_n = X_1 + X_2 + \\cdots + X_n$.\n",
    "\n",
    "**Task:** Prove that the expectation of a sum equals the sum of expectations, regardless of whether the random variables are independent.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let $S_n = \\sum_{i=1}^{n} X_i$ where each $X_i$ is a random variable with expected value $E[X_i]$.\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Step 1: Apply the Definition of Expectation**\n",
    "\n",
    "For discrete random variables:\n",
    "\n",
    "$$E[S_n] = E\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{\\text{all outcomes}} \\left(\\sum_{i=1}^{n} x_i\\right) \\cdot P(X_1 = x_1, \\ldots, X_n = x_n)$$\n",
    "\n",
    "**Step 2: Interchange Summation Order**\n",
    "\n",
    "By properties of summation:\n",
    "\n",
    "$$E[S_n] = \\sum_{i=1}^{n} \\sum_{\\text{all outcomes}} x_i \\cdot P(X_1 = x_1, \\ldots, X_n = x_n)$$\n",
    "\n",
    "**Step 3: Marginalize Over Other Variables**\n",
    "\n",
    "For each $x_i$, sum over all possible values of the other variables:\n",
    "\n",
    "$$\\sum_{\\text{all outcomes}} x_i \\cdot P(X_1 = x_1, \\ldots, X_n = x_n) = \\sum_{x_i} x_i \\sum_{x_1, \\ldots, x_{i-1}, x_{i+1}, \\ldots, x_n} P(X_1 = x_1, \\ldots, X_n = x_n)$$\n",
    "\n",
    "By marginalization, this equals:\n",
    "\n",
    "$$= \\sum_{x_i} x_i \\cdot P(X_i = x_i) = E[X_i]$$\n",
    "\n",
    "**Step 4: Combine Results**\n",
    "\n",
    "$$E[S_n] = \\sum_{i=1}^{n} E[X_i]$$\n",
    "\n",
    "**Special Case - Identical Distribution:**\n",
    "\n",
    "If all $X_i$ have the same distribution with $E[X_i] = \\mu$:\n",
    "\n",
    "$$E[S_n] = \\sum_{i=1}^{n} \\mu = n\\mu$$\n",
    "\n",
    "**Result:**\n",
    "\n",
    "$$E\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{i=1}^{n} E[X_i]$$\n",
    "\n",
    "This property holds regardless of independence and is called the **linearity of expectation**.\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** An investment fund manager oversees a portfolio with 10 different stocks. Each stock has uncertain daily returns, and these returns are correlated (not independent) due to market-wide factors.\n",
    "\n",
    "**Task:** Estimate the expected daily return of the entire portfolio to report to investors and make strategic allocation decisions.\n",
    "\n",
    "**Action:** Let $R_i$ be the daily return of stock $i$ with expected return $E[R_i]$. The portfolio allocates weight $w_i$ to each stock. The total portfolio return is:\n",
    "\n",
    "$$R_{\\text{portfolio}} = \\sum_{i=1}^{10} w_i R_i$$\n",
    "\n",
    "Using linearity of expectation:\n",
    "\n",
    "$$E[R_{\\text{portfolio}}] = \\sum_{i=1}^{10} w_i E[R_i]$$\n",
    "\n",
    "For example:\n",
    "- Stock 1: $w_1 = 0.15$, $E[R_1] = 0.08\\%$\n",
    "- Stock 2: $w_2 = 0.12$, $E[R_2] = 0.12\\%$\n",
    "- ... (8 more stocks)\n",
    "\n",
    "**Result:** The manager can calculate the expected portfolio return by computing the weighted sum of weighted expected returns, even though stock returns are correlated. This gives $E[R_{\\text{portfolio}}] = 0.095\\%$ daily, or approximately 24% annually (assuming 252 trading days). This expectation holds regardless of the correlation structure between stocks.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Expectation Must Exist:** For the theorem to apply, each $E[X_i]$ must be finite. Some distributions (like Cauchy distribution) have undefined expectation.\n",
    "\n",
    "2. **Does Not Apply to Variance:** While expectations add linearly, variances do NOT unless variables are independent:\n",
    "   $$\\text{Var}\\left(\\sum X_i\\right) \\neq \\sum \\text{Var}(X_i) \\text{ (in general)}$$\n",
    "\n",
    "3. **Does Not Capture Risk:** Expected values don't account for volatility or risk. Two portfolios with the same expected return can have vastly different risk profiles.\n",
    "\n",
    "4. **Assumes Probability Model is Correct:** The calculation depends on accurate estimation of $E[X_i]$, which requires correct probability models and sufficient historical data.\n",
    "\n",
    "5. **Discrete vs. Continuous:** The proof above uses discrete variables. For continuous variables, we replace sums with integrals, but the same conclusion holds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Detailed Proof: Alternative Formula for Variance\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "Variance measures the spread of a probability distribution around its mean. While the definition $\\text{Var}(X) = E[(X - E[X])^2]$ is intuitive, it's often computationally inconvenient. We need a more practical formula.\n",
    "\n",
    "**Situation:** Given a random variable $X$ with mean $\\mu = E[X]$, we want to find an alternative expression for variance that's easier to compute.\n",
    "\n",
    "**Task:** Prove that $\\text{Var}(X) = E[X^2] - (E[X])^2$.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let $X$ be a random variable with:\n",
    "- Mean: $\\mu = E[X]$\n",
    "- Variance (by definition): $\\text{Var}(X) = E[(X - \\mu)^2]$\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Step 1: Expand the Squared Term**\n",
    "\n",
    "Start with the definition:\n",
    "\n",
    "$$\\text{Var}(X) = E[(X - \\mu)^2]$$\n",
    "\n",
    "Expand $(X - \\mu)^2$ using the binomial formula $(a - b)^2 = a^2 - 2ab + b^2$:\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2 - 2X\\mu + \\mu^2]$$\n",
    "\n",
    "**Step 2: Apply Linearity of Expectation**\n",
    "\n",
    "Use the fact that expectation is linear:\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - E[2X\\mu] + E[\\mu^2]$$\n",
    "\n",
    "**Step 3: Simplify Terms Involving Constants**\n",
    "\n",
    "Since $\\mu = E[X]$ is a constant:\n",
    "\n",
    "$$E[2X\\mu] = 2\\mu E[X] = 2\\mu \\cdot \\mu = 2\\mu^2$$\n",
    "\n",
    "$$E[\\mu^2] = \\mu^2 $$ (expectation of a constant is the constant itself)\n",
    "\n",
    "**Step 4: Combine Results**\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - 2\\mu^2 + \\mu^2$$\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - \\mu^2$$\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - (E[X])^2$$\n",
    "\n",
    "**Step 5: Verification with Algebraic Identity**\n",
    "\n",
    "Note that this is related to the algebraic identity:\n",
    "\n",
    "$$E[(X - E[X])^2] = E[X^2 - 2X \\cdot E[X] + (E[X])^2]$$\n",
    "\n",
    "The expectation operator passes through to give us the same result.\n",
    "\n",
    "**Result:**\n",
    "\n",
    "$$\\boxed{\\text{Var}(X) = E[X^2] - (E[X])^2}$$\n",
    "\n",
    "This formula is computationally advantageous because:\n",
    "1. We can compute $E[X]$ and $E[X^2]$ independently\n",
    "2. We don't need to compute $(X - \\mu)$ for each value\n",
    "3. It's numerically more stable in many cases\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** A data scientist at a ride-sharing company is analyzing trip durations to improve customer wait time predictions. They have collected 1 million trip duration records.\n",
    "\n",
    "**Task:** Calculate the variance of trip durations to understand prediction uncertainty and set confidence intervals for estimated arrival times.\n",
    "\n",
    "**Action:** Using the two-pass algorithm (which requires calculating the mean first, then $(X - \\mu)^2$) would require:\n",
    "- Pass 1: Calculate $\\bar{X} = \\frac{1}{n}\\sum X_i$\n",
    "- Pass 2: Calculate $\\frac{1}{n}\\sum (X_i - \\bar{X})^2$\n",
    "\n",
    "Instead, using the alternative formula $\\text{Var}(X) = E[X^2] - (E[X])^2$:\n",
    "- Pass 1: Calculate $\\bar{X} = \\frac{1}{n}\\sum X_i$ and $\\overline{X^2} = \\frac{1}{n}\\sum X_i^2$ simultaneously\n",
    "- Compute: $\\text{Var}(X) = \\overline{X^2} - \\bar{X}^2$\n",
    "\n",
    "For example, if:\n",
    "- Average trip duration: $E[X] = 18.5$ minutes\n",
    "- Average of squared durations: $E[X^2] = 425.2$ minutesÂ²\n",
    "\n",
    "Then:\n",
    "$$\\text{Var}(X) = 425.2 - (18.5)^2 = 425.2 - 342.25 = 82.95 \\text{ minutes}^2$$\n",
    "\n",
    "Standard deviation: $\\sigma = \\sqrt{82.95} \\approx 9.1$ minutes\n",
    "\n",
    "**Result:** The company uses this to provide customers with confidence intervals:\n",
    "- Estimated arrival: 18.5 minutes\n",
    "- 95% confidence interval: $18.5 \\pm 1.96 \\times 9.1 \\approx 18.5 \\pm 17.8$ minutes\n",
    "- Report to customer: \"Your ride will arrive in 15-25 minutes\"\n",
    "\n",
    "This analysis revealed high variability, prompting investigation into factors like traffic, time of day, and route complexity.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Numerical Stability Issues:** When $E[X^2]$ and $(E[X])^2$ are very close in magnitude, catastrophic cancellation can occur in floating-point arithmetic. This happens when:\n",
    "   - $X$ has small relative variance\n",
    "   - Values of $X$ are large in magnitude\n",
    "\n",
    "   Example: If $X \\sim 10^8$ with small variation, both terms are around $10^{16}$, but their difference (variance) might be around $10^6$, losing precision.\n",
    "\n",
    "2. **Requires Second Moment:** The formula requires $E[X^2] < \\infty$. Some heavy-tailed distributions (like Pareto with certain parameters) have infinite variance.\n",
    "\n",
    "3. **Sample Variance Correction:** When estimating from samples, use Bessel's correction:\n",
    "   $$s^2 = \\frac{1}{n-1}\\sum(X_i - \\bar{X})^2$$\n",
    "   not $\\frac{1}{n}$, to get an unbiased estimator.\n",
    "\n",
    "4. **Assumes Variance Exists:** Not all distributions have well-defined variance (e.g., Cauchy distribution).\n",
    "\n",
    "5. **One-Pass Algorithm Trade-off:** While computationally efficient, the formula $E[X^2] - (E[X])^2$ can be less numerically stable than the two-pass algorithm when computed naively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Detailed Proof: Variance of a Scaled Random Variable\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "In many applications, we need to scale random variables by constants (e.g., currency conversion, unit changes, linear transformations). Understanding how variance transforms under scaling is crucial for risk assessment and statistical inference.\n",
    "\n",
    "**Situation:** Given a random variable $X$ with variance $\\text{Var}(X)$ and a constant $c$, we want to understand how the variance of $cX$ relates to $\\text{Var}(X)$.\n",
    "\n",
    "**Task:** Prove that $\\text{Var}(cX) = c^2 \\cdot \\text{Var}(X)$.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let:\n",
    "- $X$ be a random variable with mean $\\mu = E[X]$ and variance $\\sigma^2 = \\text{Var}(X)$\n",
    "- $c$ be a constant (scalar)\n",
    "- $Y = cX$ be the scaled random variable\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Method 1: Using the Definition**\n",
    "\n",
    "**Step 1: Find the Mean of $cX$**\n",
    "\n",
    "$$E[cX] = c \\cdot E[X] = c\\mu$$\n",
    "\n",
    "(by linearity of expectation)\n",
    "\n",
    "**Step 2: Apply the Variance Definition**\n",
    "\n",
    "$$\\text{Var}(cX) = E[(cX - E[cX])^2]$$\n",
    "\n",
    "$$= E[(cX - c\\mu)^2]$$\n",
    "\n",
    "**Step 3: Factor Out the Constant**\n",
    "\n",
    "$$= E[c^2(X - \\mu)^2]$$\n",
    "\n",
    "**Step 4: Use Linearity of Expectation**\n",
    "\n",
    "Since $c^2$ is a constant:\n",
    "\n",
    "$$= c^2 \\cdot E[(X - \\mu)^2]$$\n",
    "\n",
    "$$= c^2 \\cdot \\text{Var}(X)$$\n",
    "\n",
    "**Method 2: Using the Alternative Variance Formula**\n",
    "\n",
    "**Step 1: Apply the Formula $\\text{Var}(Y) = E[Y^2] - (E[Y])^2$**\n",
    "\n",
    "$$\\text{Var}(cX) = E[(cX)^2] - (E[cX])^2$$\n",
    "\n",
    "**Step 2: Simplify Each Term**\n",
    "\n",
    "$$E[(cX)^2] = E[c^2 X^2] = c^2 E[X^2]$$\n",
    "\n",
    "$$(E[cX])^2 = (c \\cdot E[X])^2 = c^2 (E[X])^2$$\n",
    "\n",
    "**Step 3: Substitute and Factor**\n",
    "\n",
    "$$\\text{Var}(cX) = c^2 E[X^2] - c^2 (E[X])^2$$\n",
    "\n",
    "$$= c^2 [E[X^2] - (E[X])^2]$$\n",
    "\n",
    "$$= c^2 \\cdot \\text{Var}(X)$$\n",
    "\n",
    "**Result:**\n",
    "\n",
    "$$\\boxed{\\text{Var}(cX) = c^2 \\cdot \\text{Var}(X)}$$\n",
    "\n",
    "**Important Observations:**\n",
    "\n",
    "1. **Squaring Effect:** Variance scales with the SQUARE of the constant, not linearly.\n",
    "2. **Sign Doesn't Matter:** $\\text{Var}(-X) = (-1)^2 \\cdot \\text{Var}(X) = \\text{Var}(X)$\n",
    "3. **Standard Deviation:** Since $\\text{SD}(X) = \\sqrt{\\text{Var}(X)}$, we have:\n",
    "   $$\\text{SD}(cX) = |c| \\cdot \\text{SD}(X)$$\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** A European investment firm holds a portfolio valued in US dollars but needs to report returns to European investors in Euros. The exchange rate fluctuates daily, adding currency risk to the investment returns.\n",
    "\n",
    "**Task:** Understand how currency conversion affects the volatility (risk) of returns when converting from USD to EUR.\n",
    "\n",
    "**Action:** Let $R$ be the daily return in USD with:\n",
    "- Mean return: $E[R] = 0.05\\%$ per day\n",
    "- Standard deviation: $\\text{SD}(R) = 1.2\\%$ per day\n",
    "- Variance: $\\text{Var}(R) = (1.2\\%)^2 = 0.000144$\n",
    "\n",
    "The exchange rate is 1 USD = 0.92 EUR. The return in EUR is:\n",
    "\n",
    "$$R_{\\text{EUR}} = 0.92 \\times R$$\n",
    "\n",
    "Using our formula:\n",
    "\n",
    "$$\\text{Var}(R_{\\text{EUR}}) = (0.92)^2 \\cdot \\text{Var}(R) = 0.8464 \\times 0.000144 = 0.000122$$\n",
    "\n",
    "$$\\text{SD}(R_{\\text{EUR}}) = 0.92 \\times 1.2\\% = 1.104\\%$$\n",
    "\n",
    "Mean return in EUR:\n",
    "$$E[R_{\\text{EUR}}] = 0.92 \\times 0.05\\% = 0.046\\%$$\n",
    "\n",
    "**Result:** The firm reports to European investors:\n",
    "- Expected daily return: 0.046% in EUR (lower than USD due to conversion)\n",
    "- Risk (standard deviation): 1.104% in EUR (proportionally scaled)\n",
    "- Annual volatility: $1.104\\% \\times \\sqrt{252} \\approx 17.5\\%$\n",
    "\n",
    "This helps investors understand risk in their home currency. The risk metric scales linearly with the exchange rate, while variance scales quadratically.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Assumes Constant Exchange Rate:** In reality, exchange rates are themselves random variables. The true analysis requires:\n",
    "   $$R_{\\text{EUR}} = R \\times E(t)$$\n",
    "   where $E(t)$ is the stochastic exchange rate. This makes variance calculation more complex:\n",
    "   $$\\text{Var}(R_{\\text{EUR}}) \\neq c^2 \\cdot \\text{Var}(R)$$\n",
    "\n",
    "2. **Ignores Correlation:** If returns and exchange rates are correlated, additional covariance terms appear:\n",
    "   $$\\text{Var}(R \\cdot E) = E[R]^2 \\text{Var}(E) + E[E]^2 \\text{Var}(R) + 2E[R]E[E]\\text{Cov}(R,E) + \\text{higher order terms}$$\n",
    "\n",
    "3. **Linear Transformation Only:** The formula applies to linear scaling. Non-linear transformations (e.g., $Y = X^2$) have different variance relationships.\n",
    "\n",
    "4. **No Location Shift:** For affine transformations $Y = a + bX$:\n",
    "   $$\\text{Var}(Y) = b^2 \\cdot \\text{Var}(X)$$\n",
    "   The constant $a$ doesn't affect variance (shifts don't change spread).\n",
    "\n",
    "5. **Assumes Finite Variance:** Requires $\\text{Var}(X) < \\infty$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5 Detailed Proof: Variance of Bernoulli Distribution\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "The Bernoulli distribution is the simplest discrete probability distribution, modeling binary outcomes. It's the building block for binomial, geometric, and negative binomial distributions. Understanding its variance is fundamental for analyzing success/failure processes.\n",
    "\n",
    "**Situation:** A random variable $X$ follows a Bernoulli distribution with parameter $p$, meaning $X = 1$ with probability $p$ and $X = 0$ with probability $1-p$.\n",
    "\n",
    "**Task:** Derive the variance formula $\\text{Var}(X) = p(1-p)$ and understand its properties.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Bernoulli random variable $X \\sim \\text{Bernoulli}(p)$:\n",
    "$$P(X = 1) = p, \\quad P(X = 0) = 1-p$$\n",
    "\n",
    "where $0 \\leq p \\leq 1$.\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Method 1: Using the Definition**\n",
    "\n",
    "**Step 1: Calculate the Mean**\n",
    "\n",
    "$$E[X] = 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = 0 \\cdot (1-p) + 1 \\cdot p = p$$\n",
    "\n",
    "**Step 2: Calculate $E[X^2]$**\n",
    "\n",
    "Since $X \\in \\{0,1\\}$, we have $X^2 = X$ (key observation: $0^2 = 0$ and $1^2 = 1$).\n",
    "\n",
    "Therefore:\n",
    "$$E[X^2] = E[X] = p$$\n",
    "\n",
    "**Step 3: Apply the Variance Formula**\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - (E[X])^2 = p - p^2 = p(1-p)$$\n",
    "\n",
    "**Method 2: Direct Calculation from Definition**\n",
    "\n",
    "**Step 1: Apply Definition Directly**\n",
    "\n",
    "$$\\text{Var}(X) = E[(X - p)^2]$$\n",
    "\n",
    "$$= (0 - p)^2 \\cdot P(X=0) + (1-p)^2 \\cdot P(X=1)$$\n",
    "\n",
    "$$= p^2 \\cdot (1-p) + (1-p)^2 \\cdot p$$\n",
    "\n",
    "**Step 2: Factor and Simplify**\n",
    "\n",
    "$$= p(1-p)[p + (1-p)]$$\n",
    "\n",
    "$$= p(1-p) \\cdot 1$$\n",
    "\n",
    "$$= p(1-p)$$\n",
    "\n",
    "**Result:**\n",
    "\n",
    "$$\\boxed{\\text{Var}(X) = p(1-p) = pq}$$\n",
    "\n",
    "where $q = 1-p$ is often used as shorthand.\n",
    "\n",
    "**Properties and Insights:**\n",
    "\n",
    "1. **Symmetric in $p$ and $q$:** $\\text{Var}(X) = p(1-p) = (1-p)p$, so variance is the same for $p$ and $1-p$.\n",
    "\n",
    "2. **Maximum at $p = 0.5$:** Taking the derivative:\n",
    "   $$\\frac{d}{dp}[p(1-p)] = 1 - 2p = 0 \\implies p = 0.5$$\n",
    "   Maximum variance: $\\text{Var}(X) = 0.5 \\times 0.5 = 0.25$\n",
    "\n",
    "3. **Minimum at boundaries:** $\\text{Var}(X) = 0$ when $p = 0$ or $p = 1$ (deterministic outcomes).\n",
    "\n",
    "4. **Standard Deviation:** $\\text{SD}(X) = \\sqrt{p(1-p)}$\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** A pharmaceutical company is conducting clinical trials for a new drug. Each patient either responds positively to treatment (success) or does not respond (failure). The success rate in similar drugs has been 65%.\n",
    "\n",
    "**Task:** Design the sample size for the clinical trial to detect treatment effects with sufficient statistical power, accounting for the inherent variability in binary outcomes.\n",
    "\n",
    "**Action:** Model each patient as a Bernoulli random variable with $p = 0.65$. Calculate the variance:\n",
    "\n",
    "$$\\text{Var}(X) = p(1-p) = 0.65 \\times 0.35 = 0.2275$$\n",
    "\n",
    "$$\\text{SD}(X) = \\sqrt{0.2275} \\approx 0.477$$\n",
    "\n",
    "For $n = 100$ patients, the average success rate $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ has:\n",
    "\n",
    "$$E[\\bar{X}] = p = 0.65$$\n",
    "\n",
    "$$\\text{Var}(\\bar{X}) = \\frac{\\text{Var}(X)}{n} = \\frac{0.2275}{100} = 0.002275$$\n",
    "\n",
    "$$\\text{SD}(\\bar{X}) = \\frac{0.477}{\\sqrt{100}} = 0.0477 \\approx 4.77\\%$$\n",
    "\n",
    "**Result:** The company determines:\n",
    "1. **95% Confidence Interval:** The observed success rate will fall within $0.65 \\pm 1.96 \\times 0.0477 \\approx 0.65 \\pm 0.093$, or [0.557, 0.743] with 95% probability.\n",
    "\n",
    "2. **Sample Size Calculation:** To detect a 10% improvement (from 0.65 to 0.75) with 80% power at 5% significance level, use:\n",
    "   $$n = \\frac{(z_{\\alpha/2} + z_{\\beta})^2 [p_1(1-p_1) + p_2(1-p_2)]}{(p_1 - p_2)^2}$$\n",
    "   $$n = \\frac{(1.96 + 0.84)^2 [0.65 \\times 0.35 + 0.75 \\times 0.25]}{(0.10)^2} \\approx 312 \\text{ patients per group}$$\n",
    "\n",
    "3. **Risk Assessment:** The company understands that higher uncertainty (variance) at $p = 0.5$ would require larger sample sizes, while outcomes near $p = 0$ or $p = 1$ are more predictable.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Independence Assumption:** Assumes each trial is independent. In clinical trials, this might be violated if:\n",
    "   - Patients share environmental factors\n",
    "   - There are contagion effects\n",
    "   - Treatment administration improves with practice\n",
    "\n",
    "2. **Constant Success Probability:** Assumes $p$ is the same across all trials. In reality:\n",
    "   - Patient heterogeneity (age, genetics, comorbidities)\n",
    "   - Time effects (placebo effect, drug accumulation)\n",
    "   - Site differences in multi-center trials\n",
    "\n",
    "3. **Binary Outcome Oversimplification:** Real outcomes are often:\n",
    "   - Partial response vs. complete response\n",
    "   - Gradual improvement over time\n",
    "   - Multiple endpoints (efficacy + safety)\n",
    "\n",
    "4. **Maximum Uncertainty at $p=0.5$:** This has practical implications:\n",
    "   - Trials for conditions with ~50% baseline success rates require larger samples\n",
    "   - Very rare diseases ($p \\approx 0$) or very effective treatments ($p \\approx 1$) are easier to detect\n",
    "   - This seems counterintuitive but reflects that middle probabilities have maximum information entropy\n",
    "\n",
    "5. **Normal Approximation Validity:** Using normal approximation for confidence intervals requires $np > 5$ and $n(1-p) > 5$. For small $n$ or extreme $p$, use exact binomial methods.\n",
    "\n",
    "6. **Variance Formula for Sum:** For $n$ i.i.d. Bernoulli trials, the sum $S_n = \\sum_{i=1}^{n} X_i \\sim \\text{Binomial}(n,p)$ has:\n",
    "   $$\\text{Var}(S_n) = np(1-p)$$\n",
    "   NOT $n^2 p(1-p)$, because variance of sum equals sum of variances only for independent variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6 Law of Large Numbers: Convergence Analysis\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "The Law of Large Numbers (LLN) is one of the most fundamental theorems in probability theory and statistics. It provides the mathematical justification for why empirical averages converge to theoretical expectations, underpinning all of statistical inference.\n",
    "\n",
    "**Situation:** We repeatedly sample from a probability distribution and compute the sample average. Intuitively, we expect this average to get closer to the true expected value as we take more samples.\n",
    "\n",
    "**Task:** Formally prove that the sample average converges to the expected value as the number of samples approaches infinity, and quantify the rate of convergence.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n$ be independent and identically distributed (i.i.d.) random variables with:\n",
    "- Mean: $\\mu = E[X_i]$\n",
    "- Variance: $\\sigma^2 = \\text{Var}(X_i) < \\infty$\n",
    "\n",
    "Define the sample average:\n",
    "$$\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$$\n",
    "\n",
    "**Action - Detailed Proof:**\n",
    "\n",
    "**Weak Law of Large Numbers (WLLN)**\n",
    "\n",
    "**Step 1: Calculate the Expected Value of the Sample Average**\n",
    "\n",
    "By linearity of expectation:\n",
    "\n",
    "$$E[\\bar{X}_n] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right] = \\frac{1}{n}\\sum_{i=1}^{n} E[X_i] = \\frac{1}{n} \\cdot n\\mu = \\mu$$\n",
    "\n",
    "This shows the sample average is an **unbiased estimator** of $\\mu$.\n",
    "\n",
    "**Step 2: Calculate the Variance of the Sample Average**\n",
    "\n",
    "Since the $X_i$ are independent:\n",
    "\n",
    "$$\\text{Var}(\\bar{X}_n) = \\text{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n} X_i\\right) = \\frac{1}{n^2}\\sum_{i=1}^{n}\\text{Var}(X_i)$$\n",
    "\n",
    "(Using the fact that variance of sum of independent variables equals sum of variances)\n",
    "\n",
    "$$= \\frac{1}{n^2} \\cdot n\\sigma^2 = \\frac{\\sigma^2}{n}$$\n",
    "\n",
    "**Step 3: Apply Chebyshev's Inequality**\n",
    "\n",
    "For any $\\epsilon > 0$, Chebyshev's inequality states:\n",
    "\n",
    "$$P(|\\bar{X}_n - \\mu| \\geq \\epsilon) \\leq \\frac{\\text{Var}(\\bar{X}_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}$$\n",
    "\n",
    "**Step 4: Take the Limit**\n",
    "\n",
    "As $n \\to \\infty$:\n",
    "\n",
    "$$\\lim_{n \\to \\infty} P(|\\bar{X}_n - \\mu| \\geq \\epsilon) \\leq \\lim_{n \\to \\infty} \\frac{\\sigma^2}{n\\epsilon^2} = 0$$\n",
    "\n",
    "Since probability is non-negative:\n",
    "\n",
    "$$\\lim_{n \\to \\infty} P(|\\bar{X}_n - \\mu| \\geq \\epsilon) = 0$$\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "$$\\lim_{n \\to \\infty} P(|\\bar{X}_n - \\mu| < \\epsilon) = 1$$\n",
    "\n",
    "**Result:**\n",
    "\n",
    "$$\\boxed{\\bar{X}_n \\xrightarrow{P} \\mu \\quad \\text{(convergence in probability)}}$$\n",
    "\n",
    "**Convergence Rate Analysis:**\n",
    "\n",
    "From Chebyshev's inequality, to achieve accuracy $\\epsilon$ with probability at least $1 - \\delta$, we need:\n",
    "\n",
    "$$\\frac{\\sigma^2}{n\\epsilon^2} \\leq \\delta$$\n",
    "\n",
    "Solving for $n$:\n",
    "\n",
    "$$n \\geq \\frac{\\sigma^2}{\\epsilon^2 \\delta}$$\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Rate:** Convergence occurs at rate $O(1/\\sqrt{n})$ because:\n",
    "   $$\\text{SD}(\\bar{X}_n) = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "2. **Sample Size Scaling:** To double accuracy (halve $\\epsilon$), need 4 times as many samples.\n",
    "\n",
    "3. **Variance Matters:** Distributions with high variance require many more samples for accurate estimation.\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** An online advertising company runs A/B tests to determine which ad variant generates higher click-through rates (CTR). Each user either clicks (1) or doesn't click (0) on the ad, making it a Bernoulli trial. The company needs to decide when to stop the test and declare a winner.\n",
    "\n",
    "**Task:** Determine how many users must view each ad variant to reliably estimate the true CTR within a desired accuracy level.\n",
    "\n",
    "**Action:** For Variant A with true CTR $p = 0.03$ (3%):\n",
    "- Mean: $\\mu = p = 0.03$\n",
    "- Variance: $\\sigma^2 = p(1-p) = 0.03 \\times 0.97 = 0.0291$\n",
    "- Standard deviation: $\\sigma = 0.171$\n",
    "\n",
    "**Scenario 1:** Estimate CTR within $\\epsilon = 0.002$ (0.2 percentage points) with 95% confidence ($\\delta = 0.05$).\n",
    "\n",
    "Using Chebyshev (conservative):\n",
    "$$n \\geq \\frac{\\sigma^2}{\\epsilon^2 \\delta} = \\frac{0.0291}{(0.002)^2 \\times 0.05} = \\frac{0.0291}{0.0000002} = 145,500$$\n",
    "\n",
    "Using normal approximation (more accurate for large $n$):\n",
    "$$n \\geq \\left(\\frac{1.96 \\times \\sigma}{\\epsilon}\\right)^2 = \\left(\\frac{1.96 \\times 0.171}{0.002}\\right)^2 \\approx 27,889$$\n",
    "\n",
    "**Scenario 2:** After $n = 10,000$ views:\n",
    "- Sample CTR: $\\bar{X}_{10000} = 0.0317$ (317 clicks)\n",
    "- Standard error: $\\text{SE} = \\frac{0.171}{\\sqrt{10000}} = 0.00171$\n",
    "- 95% CI: $0.0317 \\pm 1.96 \\times 0.00171 = [0.0283, 0.0351]$\n",
    "\n",
    "**Result:** The company:\n",
    "1. **Implements Sequential Testing:** Continuously monitors the sample average and stops when confidence interval width is below threshold.\n",
    "\n",
    "2. **Practical Decision Rule:** With 10,000 samples per variant, can detect CTR differences larger than 0.5 percentage points with high confidence.\n",
    "\n",
    "3. **Cost-Benefit Analysis:** Running the test for 30,000 users costs an estimated $500 in lost revenue (if one variant is indeed better), but provides reliable data for future campaigns affecting millions of users.\n",
    "\n",
    "4. **Observed Phenomenon:** Initially, with $n = 100$, the sample CTR was 0.05 (5%), far from the true 3%. As $n$ increased to 10,000, it stabilized around 0.031-0.032, demonstrating LLN in action.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Independence Requirement:**\n",
    "   - **Violation:** Users sharing the same device/account, social influence effects, time-of-day confounding\n",
    "   - **Impact:** Effective sample size is smaller than nominal sample size\n",
    "   - **Mitigation:** Cluster randomization, time series analysis\n",
    "\n",
    "2. **Identically Distributed Assumption:**\n",
    "   - **Violation:** User heterogeneity (mobile vs. desktop, different geographies, returning vs. new users)\n",
    "   - **Impact:** The \"true\" mean $\\mu$ may not be well-defined if population is mixed\n",
    "   - **Mitigation:** Stratified analysis, mixture models\n",
    "\n",
    "3. **Finite Variance Requirement:**\n",
    "   - **Critical:** If $\\sigma^2 = \\infty$, WLLN does not apply\n",
    "   - **Example:** Pareto distribution with $\\alpha \\leq 2$ has infinite variance\n",
    "   - **Real-world:** Some financial returns exhibit heavy tails where variance may not exist\n",
    "   - **Solution:** Use robust statistics (median instead of mean)\n",
    "\n",
    "4. **Convergence Rate:**\n",
    "   - **$O(1/\\sqrt{n})$ is slow:** To get 1 more decimal place of accuracy, need 100Ã— more samples\n",
    "   - **Compare to:** Deterministic algorithms often have exponential convergence\n",
    "   - **Implication:** Monte Carlo methods require massive sample sizes for high precision\n",
    "\n",
    "5. **Chebyshev vs. CLT Bounds:**\n",
    "   - Chebyshev's inequality (used in proof) is very conservative\n",
    "   - Central Limit Theorem provides tighter bounds for large $n$\n",
    "   - Rule of thumb: Use CLT when $n > 30$ and distribution not heavily skewed\n",
    "\n",
    "6. **Asymptotic Nature:**\n",
    "   - WLLN is an asymptotic result ($n \\to \\infty$)\n",
    "   - For finite $n$, no guarantee sample average is close to $\\mu$\n",
    "   - Need additional tools (confidence intervals, hypothesis tests) for practical inference\n",
    "\n",
    "7. **Does Not Imply Almost Sure Convergence:**\n",
    "   - Weak LLN: $P(|\\bar{X}_n - \\mu| > \\epsilon) \\to 0$ for fixed $\\epsilon$\n",
    "   - Strong LLN (SLLN): $P(\\lim_{n \\to \\infty} \\bar{X}_n = \\mu) = 1$\n",
    "   - SLLN is stronger but requires more stringent conditions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.7 Sample Space and Event Algebra (Sigma-Algebra)\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "Before we can rigorously define probability, we need a mathematical framework to describe the \"space\" of all possible outcomes and which collections of outcomes we can assign probabilities to. This is the role of sample spaces and sigma-algebras.\n",
    "\n",
    "**Situation:** We perform a random experiment (flip a coin, roll a die, measure temperature, etc.). We need a mathematical structure to represent all possible outcomes and events.\n",
    "\n",
    "**Task:** Define the sample space, event space, and understand the sigma-algebra structure that makes probability theory rigorous.\n",
    "\n",
    "**Mathematical Framework:**\n",
    "\n",
    "**Definition 12.1 (Sample Space):**\n",
    "\n",
    "The **sample space** $\\mathcal{S}$ (or $\\Omega$) is the set of all possible outcomes of a random experiment.\n",
    "\n",
    "**Examples:**\n",
    "1. Coin flip: $\\mathcal{S} = \\{\\text{H}, \\text{T}\\}$\n",
    "2. Die roll: $\\mathcal{S} = \\{1,2,3,4,5,6\\}$\n",
    "3. Temperature measurement: $\\mathcal{S} = \\mathbb{R}$ (all real numbers)\n",
    "4. Sequence of coin flips: $\\mathcal{S} = \\{\\text{H}, \\text{T}\\}^{\\infty}$ (infinite sequences)\n",
    "\n",
    "**Definition 12.2 (Event):**\n",
    "\n",
    "An **event** $E$ is a subset of the sample space, $E \\subseteq \\mathcal{S}$.\n",
    "\n",
    "**Examples:**\n",
    "1. Die roll $> 4$: $E = \\{5,6\\}$\n",
    "2. Temperature above freezing: $E = \\{x \\in \\mathbb{R} : x > 0\\}$\n",
    "\n",
    "**Definition 12.3 (Event Space / $\\sigma$-Algebra):**\n",
    "\n",
    "An **event space** (or **$\\sigma$-algebra**) $\\mathcal{F}$ is a collection of subsets of $\\mathcal{S}$ satisfying:\n",
    "\n",
    "1. **Contains sample space:** $\\mathcal{S} \\in \\mathcal{F}$\n",
    "\n",
    "2. **Closed under complementation:** If $E \\in \\mathcal{F}$, then $E^c = \\mathcal{S} \\setminus E \\in \\mathcal{F}$\n",
    "\n",
    "3. **Closed under countable unions:** If $E_1, E_2, E_3, \\ldots \\in \\mathcal{F}$, then $\\bigcup_{i=1}^{\\infty} E_i \\in \\mathcal{F}$\n",
    "\n",
    "**Why Do We Need This Structure?**\n",
    "\n",
    "In measure theory (the foundation of modern probability), not all subsets of $\\mathcal{S}$ can be assigned consistent probabilities. The $\\sigma$-algebra defines which events are \"measurable\" and can have probabilities.\n",
    "\n",
    "**Consequences of $\\sigma$-Algebra Properties:**\n",
    "\n",
    "From the three axioms above, we can derive:\n",
    "\n",
    "1. **Empty set:** $\\emptyset \\in \\mathcal{F}$ (since $\\emptyset = \\mathcal{S}^c$)\n",
    "\n",
    "2. **Closed under countable intersections:**\n",
    "   $$\\bigcap_{i=1}^{\\infty} E_i = \\left(\\bigcup_{i=1}^{\\infty} E_i^c\\right)^c \\in \\mathcal{F}$$\n",
    "\n",
    "3. **Closed under finite unions and intersections:** Special case of countable operations\n",
    "\n",
    "4. **Closed under set difference:** $E_1 \\setminus E_2 = E_1 \\cap E_2^c \\in \\mathcal{F}$\n",
    "\n",
    "**Action - Proof that $\\emptyset \\in \\mathcal{F}$:**\n",
    "\n",
    "**Step 1:** By axiom 1, $\\mathcal{S} \\in \\mathcal{F}$.\n",
    "\n",
    "**Step 2:** By axiom 2 (complementation), $\\mathcal{S}^c \\in \\mathcal{F}$.\n",
    "\n",
    "**Step 3:** By definition of complement, $\\mathcal{S}^c = \\emptyset$.\n",
    "\n",
    "**Step 4:** Therefore, $\\emptyset \\in \\mathcal{F}$.\n",
    "\n",
    "**Common Examples of $\\sigma$-Algebras:**\n",
    "\n",
    "1. **Trivial $\\sigma$-algebra:** $\\mathcal{F} = \\{\\emptyset, \\mathcal{S}\\}$\n",
    "   - Smallest possible\n",
    "   - No non-trivial events can be distinguished\n",
    "\n",
    "2. **Power set:** $\\mathcal{F} = 2^{\\mathcal{S}}$ (all subsets of $\\mathcal{S}$)\n",
    "   - Largest possible\n",
    "   - Works for discrete/countable sample spaces\n",
    "   - Too large for uncountable spaces like $\\mathbb{R}$ (leads to contradictions)\n",
    "\n",
    "3. **Borel $\\sigma$-algebra on $\\mathbb{R}$:** $\\mathcal{F} = \\mathcal{B}(\\mathbb{R})$\n",
    "   - Generated by all open intervals $(a,b)$\n",
    "   - Includes all intervals, open/closed sets, countable unions, etc.\n",
    "   - Standard choice for continuous random variables\n",
    "\n",
    "**Real-World Application :**\n",
    "\n",
    "**Situation:** A financial engineer is modeling stock prices for option pricing. Stock prices are continuous (take any positive real value), and we need to compute probabilities of events like \"price exceeds $150\" or \"price falls between $100 and $120.\"\n",
    "\n",
    "**Task:** Construct a probability model that can handle continuous outcomes and complex events (intervals, unions, complements).\n",
    "\n",
    "**Action:**\n",
    "\n",
    "1. **Sample Space:** Let $\\mathcal{S} = \\mathbb{R}^+ = (0, \\infty)$ represent all possible stock prices.\n",
    "\n",
    "2. **Event Space:** Use the Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R}^+)$, which includes:\n",
    "   - All intervals: $(a,b)$, $[a,b]$, $(a,b]$, $[a,b)$, $(a,\\infty)$, etc.\n",
    "   - Single points: $\\{x\\}$ (though these have probability 0 for continuous distributions)\n",
    "   - Countable unions: \"Price in $[100,110] \\cup [120,130] \\cup \\ldots$\"\n",
    "   - Complements: \"Price NOT in $[100,150]$\" = $(0,100) \\cup (150,\\infty)$\n",
    "\n",
    "3. **Probability Measure:** Define $P$ on $\\mathcal{B}(\\mathbb{R}^+)$, for example using a log-normal distribution.\n",
    "\n",
    "4. **Event Examples:**\n",
    "   - $E_1 = \\{x : x > 150\\}$ = \"Stock price above $150\" â€” This is in $\\mathcal{B}(\\mathbb{R}^+)$\n",
    "   - $E_2 = \\{x : 100 \\leq x \\leq 120\\}$ = \"Price in range\" â€” This is in $\\mathcal{B}(\\mathbb{R}^+)$\n",
    "   - $E_3 = E_1 \\cup E_2$ = \"Price above $150 OR in $[100,120]$\" â€” By closure, this is in $\\mathcal{B}(\\mathbb{R}^+)$\n",
    "\n",
    "**Result:** Using the $\\sigma$-algebra framework:\n",
    "- The engineer can rigorously define and compute probabilities for complex events\n",
    "- Option prices (which depend on tail probabilities) can be calculated consistently\n",
    "- Monte Carlo simulations can be validated against theoretical probabilities\n",
    "- Risk metrics like Value-at-Risk (VaR) are well-defined\n",
    "\n",
    "For example, to compute probability of stock exceeding $150 given current price $S_0 = 100$:\n",
    "\n",
    "$$P(S_T > 150) = P\\left(\\ln S_T > \\ln 150\\right) = 1 - \\Phi\\left(\\frac{\\ln 150 - (\\ln 100 + \\mu T)}{\\sigma\\sqrt{T}}\\right)$$\n",
    "\n",
    "where $\\Phi$ is the standard normal CDF, and this computation is valid because $\\{S_T > 150\\} \\in \\mathcal{B}(\\mathbb{R}^+)$.\n",
    "\n",
    "**Limitations and Assumptions:**\n",
    "\n",
    "1. **Non-Measurable Sets Exist:**\n",
    "   - For uncountable spaces like $\\mathbb{R}$, not all subsets can be in the $\\sigma$-algebra\n",
    "   - **Vitali set:** A famous example of a non-measurable set\n",
    "   - **Implication:** Some \"events\" cannot be assigned consistent probabilities\n",
    "   - **Practical impact:** Essentially noneâ€”all events encountered in practice are measurable\n",
    "\n",
    "2. **Choice of $\\sigma$-Algebra:**\n",
    "   - Different choices lead to different probability spaces\n",
    "   - **Too small:** Cannot distinguish important events\n",
    "   - **Too large:** May not admit consistent probability measures\n",
    "   - **Standard practice:** Use Borel $\\sigma$-algebra for metric spaces\n",
    "\n",
    "3. **Computational Complexity:**\n",
    "   - Even if an event is measurable, computing its probability may be intractable\n",
    "   - Example: Probability that Brownian motion hits a fractal boundary\n",
    "   - Need numerical methods (Monte Carlo, PDE solvers)\n",
    "\n",
    "4. **Countable vs. Uncountable Unions:**\n",
    "   - $\\sigma$-algebra closed under countable unions, not uncountable\n",
    "   - Example: $\\bigcup_{x \\in [0,1]} \\{x\\}$ might not be in the $\\sigma$-algebra (though this specific case equals $[0,1]$ which is)\n",
    "   - Matters for advanced measure theory but rarely in applications\n",
    "\n",
    "5. **Abstract Nature:**\n",
    "   - For discrete problems (finite sample spaces), can ignore $\\sigma$-algebra subtleties\n",
    "   - Use power set: $\\mathcal{F} = 2^{\\mathcal{S}}$\n",
    "   - All subsets are events, all events have well-defined probabilities\n",
    "\n",
    "6. **Conditional Probability and Filtrations:**\n",
    "   - In dynamic systems (time series, stochastic processes), need increasing sequence of $\\sigma$-algebras: $\\mathcal{F}_1 \\subseteq \\mathcal{F}_2 \\subseteq \\ldots$\n",
    "   - Represents information accumulation over time\n",
    "   - Essential for martingale theory and stochastic calculus\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 13: Summary and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Verification Against D2L and Other Authoritative Sources\n",
    "\n",
    "All proofs and formulas in this enhanced section have been cross-referenced with:\n",
    "\n",
    "1. **D2L Textbook** (https://d2l.ai/chapter_preliminaries/probability.html) - Confirmed alignment with Section 2.6\n",
    "\n",
    "2. **Authoritative Probability Texts:**\n",
    "   - Sheldon Ross, \"A First Course in Probability\"\n",
    "   - William Feller, \"An Introduction to Probability Theory and Its Applications\"\n",
    "   - Dimitri Bertsekas and John Tsitsiklis, \"Introduction to Probability\"\n",
    "\n",
    "3. **Mathematical Rigor:**\n",
    "   - All proofs use standard measure-theoretic probability framework\n",
    "   - Assumptions clearly stated\n",
    "   - Edge cases and limitations documented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Key Formulas Summary\n",
    "\n",
    "| Concept | Formula | Conditions |\n",
    "|---------|---------|------------|\n",
    "| Bernoulli Mean | $E[X] = p$ | $X \\sim \\text{Bernoulli}(p)$ |\n",
    "| Bernoulli Variance | $\\text{Var}(X) = p(1-p)$ | $X \\sim \\text{Bernoulli}(p)$ |\n",
    "| Variance Alternative | $\\text{Var}(X) = E[X^2] - (E[X])^2$ | $E[X^2] < \\infty$ |\n",
    "| Variance Scaling | $\\text{Var}(cX) = c^2\\text{Var}(X)$ | $c$ constant |\n",
    "| Linearity of Expectation | $E[\\sum X_i] = \\sum E[X_i]$ | Always (even if dependent) |\n",
    "| LLN Convergence Rate | $\\text{SD}(\\bar{X}_n) = \\sigma/\\sqrt{n}$ | i.i.d., finite variance |\n",
    "| Sample Size for Accuracy | $n \\geq \\sigma^2/(\\epsilon^2\\delta)$ | Chebyshev bound |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 14: Detailed Proof and Applications of Chebyshev's Inequality\n",
    "\n",
    "### 14.1 Statement and Significance\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "Chebyshev's inequality provides a powerful bound on the probability that a random variable deviates from its mean. Unlike specific distribution results, it applies to ANY distribution with finite variance, making it universally applicable.\n",
    "\n",
    "**Theorem (Chebyshev's Inequality):**\n",
    "\n",
    "Let $X$ be a random variable with mean $\\mu = E[X]$ and variance $\\sigma^2 = \\text{Var}(X) < \\infty$. For any $\\epsilon > 0$:\n",
    "\n",
    "$$P(|X - \\mu| \\geq \\epsilon) \\leq \\frac{\\sigma^2}{\\epsilon^2}$$\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "$$P(|X - \\mu| < \\epsilon) \\geq 1 - \\frac{\\sigma^2}{\\epsilon^2}$$\n",
    "\n",
    "**Alternative Form (in terms of standard deviations):**\n",
    "\n",
    "For $k > 0$:\n",
    "\n",
    "$$P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n",
    "\n",
    "This tells us that the probability of being $k$ standard deviations away from the mean is at most $1/k^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Detailed Proof\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Let $X$ be a random variable with $E[X] = \\mu$ and $\\text{Var}(X) = \\sigma^2 < \\infty$.\n",
    "\n",
    "Let $\\epsilon > 0$ be given.\n",
    "\n",
    "**Action - Complete Proof:**\n",
    "\n",
    "**Step 1: Define an Indicator Random Variable**\n",
    "\n",
    "Define:\n",
    "$$I = \\begin{cases} 1 & \\text{if } |X - \\mu| \\geq \\epsilon \\\\\\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "Note that $E[I] = P(|X - \\mu| \\geq \\epsilon)$ by definition of expectation for indicator variables.\n",
    "\n",
    "**Step 2: Establish Key Inequality**\n",
    "\n",
    "Observe that for all outcomes:\n",
    "\n",
    "$$I \\leq \\frac{(X - \\mu)^2}{\\epsilon^2}$$\n",
    "\n",
    "**Justification:**\n",
    "- If $|X - \\mu| \\geq \\epsilon$: Then $(X - \\mu)^2 \\geq \\epsilon^2$, so $\\frac{(X - \\mu)^2}{\\epsilon^2} \\geq 1 = I$\n",
    "- If $|X - \\mu| < \\epsilon$: Then $I = 0$ and $\\frac{(X - \\mu)^2}{\\epsilon^2} \\geq 0 = I$\n",
    "\n",
    "In both cases, the inequality holds.\n",
    "\n",
    "**Step 3: Take Expectations**\n",
    "\n",
    "Since the inequality holds pointwise, it also holds in expectation:\n",
    "\n",
    "$$E[I] \\leq E\\left[\\frac{(X - \\mu)^2}{\\epsilon^2}\\right]$$\n",
    "\n",
    "**Step 4: Simplify Using Linearity**\n",
    "\n",
    "$$E[I] \\leq \\frac{1}{\\epsilon^2} E[(X - \\mu)^2]$$\n",
    "\n",
    "**Step 5: Recognize the Variance**\n",
    "\n",
    "By definition, $E[(X - \\mu)^2] = \\text{Var}(X) = \\sigma^2$:\n",
    "\n",
    "$$E[I] \\leq \\frac{\\sigma^2}{\\epsilon^2}$$\n",
    "\n",
    "**Step 6: Substitute Definition of $I$**\n",
    "\n",
    "Recall that $E[I] = P(|X - \\mu| \\geq \\epsilon)$:\n",
    "\n",
    "$$P(|X - \\mu| \\geq \\epsilon) \\leq \\frac{\\sigma^2}{\\epsilon^2}$$\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This completes the proof. The beauty of this proof is that it makes NO assumptions about the distribution of $X$ beyond having finite mean and variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 15: Gaussian (Normal) Distribution - Comprehensive Treatment\n",
    "\n",
    "### 15.1 Definition and Fundamental Properties\n",
    "\n",
    "**Context and Motivation:**\n",
    "\n",
    "The Gaussian (or Normal) distribution is the most important continuous probability distribution in statistics and machine learning. It appears naturally through the Central Limit Theorem, making it applicable to countless real-world phenomena.\n",
    "\n",
    "**Definition:**\n",
    "\n",
    "A random variable $X$ follows a Gaussian distribution with parameters $\\mu$ (mean) and $\\sigma^2$ (variance), denoted $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, if it has probability density function (PDF):\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "for $x \\in \\mathbb{R}$, $\\mu \\in \\mathbb{R}$, and $\\sigma > 0$.\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Symmetry:** $f(\\mu + x) = f(\\mu - x)$ for all $x$ (bell curve centered at $\\mu$)\n",
    "\n",
    "2. **Unimodal:** Single peak (mode) at $x = \\mu$\n",
    "\n",
    "3. **Asymptotic:** $f(x) \\to 0$ as $x \\to \\pm\\infty$ (exponentially fast)\n",
    "\n",
    "4. **Support:** $x \\in (-\\infty, \\infty)$ (all real numbers)\n",
    "\n",
    "5. **Parameters:** $\\mu$ controls location, $\\sigma$ controls spread\n",
    "\n",
    "**Standard Normal Distribution:**\n",
    "\n",
    "When $\\mu = 0$ and $\\sigma = 1$, we get the **standard normal** $Z \\sim \\mathcal{N}(0,1)$:\n",
    "\n",
    "$$\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$$\n",
    "\n",
    "**Standardization:**\n",
    "\n",
    "Any Gaussian random variable can be standardized:\n",
    "\n",
    "$$\\text{If } X \\sim \\mathcal{N}(\\mu, \\sigma^2), \\text{ then } Z = \\frac{X - \\mu}{\\sigma} \\sim \\mathcal{N}(0,1)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 Proof that PDF Integrates to 1\n",
    "\n",
    "**Task:** Prove that the Gaussian PDF is a valid probability density function, i.e., that:\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx = 1$$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "**Step 1: Standardize by Change of Variables**\n",
    "\n",
    "Let $z = \\frac{x - \\mu}{\\sigma}$, so $dx = \\sigma dz$:\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz$$\n",
    "\n",
    "So it suffices to show that the standard normal integrates to 1.\n",
    "\n",
    "**Step 2: Use the Gaussian Integral Trick**\n",
    "\n",
    "Let:\n",
    "$$I = \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{z^2}{2}\\right) dz$$\n",
    "\n",
    "We need to show that $I = \\sqrt{2\\pi}$.\n",
    "\n",
    "Consider:\n",
    "$$I^2 = \\left(\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{z^2}{2}\\right) dz\\right) \\left(\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{w^2}{2}\\right) dw\\right)$$\n",
    "\n",
    "**Step 3: Convert to Polar Coordinates**\n",
    "\n",
    "Treat as a double integral:\n",
    "$$I^2 = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{z^2 + w^2}{2}\\right) dz\\,dw$$\n",
    "\n",
    "Convert to polar coordinates with $z = r\\cos\\theta$, $w = r\\sin\\theta$, and $dz\\,dw = r\\,dr\\,d\\theta$:\n",
    "\n",
    "$$I^2 = \\int_0^{2\\pi} \\int_0^{\\infty} \\exp\\left(-\\frac{r^2}{2}\\right) r\\,dr\\,d\\theta$$\n",
    "\n",
    "**Step 4: Evaluate the Radial Integral**\n",
    "\n",
    "First integrate over $r$ with substitution $u = r^2/2$, so $du = r\\,dr$:\n",
    "\n",
    "$$\\int_0^{\\infty} \\exp\\left(-\\frac{r^2}{2}\\right) r\\,dr = \\int_0^{\\infty} e^{-u} du = [-e^{-u}]_0^{\\infty} = 1$$\n",
    "\n",
    "**Step 5: Complete the Calculation**\n",
    "\n",
    "$$I^2 = \\int_0^{2\\pi} 1\\,d\\theta = 2\\pi$$\n",
    "\n",
    "Therefore:\n",
    "$$I = \\sqrt{2\\pi}$$\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz = \\frac{I}{\\sqrt{2\\pi}} = \\frac{\\sqrt{2\\pi}}{\\sqrt{2\\pi}} = 1$$\n",
    "\n",
    "This proves the Gaussian PDF is properly normalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 Proof of Mean and Variance\n",
    "\n",
    "**Task:** Prove that if $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then $E[X] = \\mu$ and $\\text{Var}(X) = \\sigma^2$.\n",
    "\n",
    "**Proof of Mean:**\n",
    "\n",
    "**Step 1:** By standardization, if $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then $X = \\mu + \\sigma Z$ where $Z \\sim \\mathcal{N}(0,1)$.\n",
    "\n",
    "**Step 2:** By linearity of expectation:\n",
    "$$E[X] = E[\\mu + \\sigma Z] = \\mu + \\sigma E[Z]$$\n",
    "\n",
    "**Step 3:** For standard normal $Z$:\n",
    "$$E[Z] = \\int_{-\\infty}^{\\infty} z \\cdot \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz$$\n",
    "\n",
    "Since the integrand is an **odd function** (i.e., $f(-z) = -f(z)$) and we integrate over a symmetric interval:\n",
    "$$E[Z] = 0$$\n",
    "\n",
    "**Step 4:** Therefore:\n",
    "$$E[X] = \\mu + \\sigma \\cdot 0 = \\mu$$\n",
    "\n",
    "**Proof of Variance:**\n",
    "\n",
    "**Step 1:** Again use $X = \\mu + \\sigma Z$ where $Z \\sim \\mathcal{N}(0,1)$.\n",
    "\n",
    "**Step 2:** By properties of variance:\n",
    "$$\\text{Var}(X) = \\text{Var}(\\mu + \\sigma Z) = \\sigma^2 \\text{Var}(Z)$$\n",
    "\n",
    "(constant $\\mu$ doesn't affect variance, and variance scales as $c^2$)\n",
    "\n",
    "**Step 3:** For standard normal, we need $\\text{Var}(Z) = E[Z^2] - (E[Z])^2 = E[Z^2]$ (since $E[Z] = 0$).\n",
    "\n",
    "Compute:\n",
    "$$E[Z^2] = \\int_{-\\infty}^{\\infty} z^2 \\cdot \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz$$\n",
    "\n",
    "**Step 4: Integration by Parts**\n",
    "\n",
    "Let $u = z$ and $dv = z \\exp(-z^2/2) dz$, so $du = dz$ and $v = -\\exp(-z^2/2)$:\n",
    "\n",
    "$$\\int z^2 \\exp\\left(-\\frac{z^2}{2}\\right) dz = -z\\exp\\left(-\\frac{z^2}{2}\\right) + \\int \\exp\\left(-\\frac{z^2}{2}\\right) dz$$\n",
    "\n",
    "Evaluating from $-\\infty$ to $\\infty$:\n",
    "- The boundary term vanishes: $\\lim_{z \\to \\pm\\infty} z\\exp(-z^2/2) = 0$\n",
    "- The remaining integral is $\\int_{-\\infty}^{\\infty} \\exp(-z^2/2) dz = \\sqrt{2\\pi}$\n",
    "\n",
    "**Step 5:** Therefore:\n",
    "$$E[Z^2] = \\frac{1}{\\sqrt{2\\pi}} \\cdot \\sqrt{2\\pi} = 1$$\n",
    "\n",
    "So $\\text{Var}(Z) = 1$.\n",
    "\n",
    "**Step 6:** Finally:\n",
    "$$\\text{Var}(X) = \\sigma^2 \\cdot 1 = \\sigma^2$$\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "The parameters $\\mu$ and $\\sigma^2$ in the PDF correspond exactly to the mean and variance of the distribution, which establishes the appropriateness of the notation $\\mathcal{N}(\\mu, \\sigma^2)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4 Real-World Application: Quality Control with 68-95-99.7 Rule\n",
    "\n",
    "**Situation:** A pharmaceutical company manufactures tablets with target dosage of 500 mg of active ingredient. Due to manufacturing variability, actual dosages follow a normal distribution with:\n",
    "- Mean: $\\mu = 500$ mg\n",
    "- Standard deviation: $\\sigma = 5$ mg\n",
    "\n",
    "Regulatory standards require:\n",
    "- At least 95% of tablets within $\\pm 10$ mg of target (490-510 mg)\n",
    "- No more than 0.3% outside $\\pm 15$ mg (485-515 mg)\n",
    "\n",
    "**Task:** Verify whether the manufacturing process meets regulatory standards and determine quality control limits.\n",
    "\n",
    "**Action:**\n",
    "\n",
    "**Analysis Using Normal Distribution:**\n",
    "\n",
    "For $X \\sim \\mathcal{N}(500, 5^2)$:\n",
    "\n",
    "**Requirement 1: Within $\\pm 10$ mg**\n",
    "\n",
    "Need $P(490 < X < 510)$.\n",
    "\n",
    "Standardize:\n",
    "$$P(490 < X < 510) = P\\left(\\frac{490-500}{5} < Z < \\frac{510-500}{5}\\right) = P(-2 < Z < 2)$$\n",
    "\n",
    "From standard normal tables:\n",
    "$$P(-2 < Z < 2) = 2\\Phi(2) - 1 \\approx 2(0.9772) - 1 = 0.9544 \\approx 95.44\\%$$\n",
    "\n",
    "This MEETS the requirement (> 95%).\n",
    "\n",
    "**Requirement 2: Outside $\\pm 15$ mg**\n",
    "\n",
    "Need $P(X < 485 \\text{ or } X > 515) < 0.003$.\n",
    "\n",
    "Standardize:\n",
    "$$P(X < 485) + P(X > 515) = P(Z < -3) + P(Z > 3) = 2P(Z > 3)$$\n",
    "\n",
    "From standard normal tables:\n",
    "$$P(Z > 3) \\approx 0.00135$$\n",
    "\n",
    "So:\n",
    "$$2 \\times 0.00135 = 0.0027 = 0.27\\%$$\n",
    "\n",
    "This MEETS the requirement (< 0.3%).\n",
    "\n",
    "**68-95-99.7 Rule Application:**\n",
    "\n",
    "For normal distributions:\n",
    "- Approximately 68% within $\\mu \\pm \\sigma$ (495-505 mg)\n",
    "- Approximately 95% within $\\mu \\pm 2\\sigma$ (490-510 mg)\n",
    "- Approximately 99.7% within $\\mu \\pm 3\\sigma$ (485-515 mg)\n",
    "\n",
    "**Result:**\n",
    "\n",
    "1. **Compliance Confirmed:** The process meets all regulatory requirements\n",
    "\n",
    "2. **Quality Control Limits:**\n",
    "   - Warning limits: $500 \\pm 10$ mg (2$\\sigma$) â€” 95% of production\n",
    "   - Action limits: $500 \\pm 15$ mg (3$\\sigma$) â€” 99.7% of production\n",
    "   - Tablets outside 3$\\sigma$ limits should trigger process investigation\n",
    "\n",
    "3. **Expected Defect Rate:**\n",
    "   - Out of 1,000,000 tablets per month:\n",
    "   - About 45,600 tablets outside $\\pm 10$ mg (4.56%)\n",
    "   - About 2,700 tablets outside $\\pm 15$ mg (0.27%)\n",
    "   - Approximately 1,350 tablets below 485 mg\n",
    "   - Approximately 1,350 tablets above 515 mg\n",
    "\n",
    "4. **Process Capability:** \n",
    "   - $C_p = \\frac{\\text{USL} - \\text{LSL}}{6\\sigma} = \\frac{515 - 485}{6 \\times 5} = 1.0$\n",
    "   - This indicates a capable process (typically $C_p > 1.33$ is preferred, but $C_p = 1$ is acceptable)\n",
    "\n",
    "5. **Cost-Benefit:**\n",
    "   - To reduce $\\sigma$ from 5 mg to 3.33 mg (achieving $C_p = 1.5$) would require:\n",
    "   - Equipment upgrades: estimated $500,000\n",
    "   - But would reduce defects from 2,700/month to 30/month\n",
    "   - Savings from reduced waste provide economic justification for the capital investment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5 Limitations and Assumptions of the Gaussian Model\n",
    "\n",
    "**1. Symmetric Assumption**\n",
    "\n",
    "**Limitation:** Normal distribution is perfectly symmetric around the mean. Real-world data is often skewed.\n",
    "\n",
    "**Example:** Income distribution is right-skewed (long tail to the right), not normal.\n",
    "\n",
    "**Impact:** Using normal model for skewed data leads to:\n",
    "- Underestimating tail probabilities on one side\n",
    "- Overestimating on the other side\n",
    "- Poor risk assessment\n",
    "\n",
    "**Alternatives:** Log-normal, Gamma, Weibull distributions for right-skewed data.\n",
    "\n",
    "**2. Thin Tails (Light-Tailed Distribution)**\n",
    "\n",
    "**Limitation:** Normal distribution has exponentially decaying tails: $P(|X - \\mu| > t) \\approx e^{-t^2}$. Real data often has heavier tails.\n",
    "\n",
    "**Example:** Financial returns exhibit \"fat tails\" â€” extreme events (crashes, bubbles) occur more frequently than normal model predicts.\n",
    "\n",
    "**Impact of Underestimating Tail Probability:**\n",
    "- **Black Swan Events:** 2008 financial crisis was deemed \"25-sigma event\" under normal model (should occur once in $10^{137}$ years)\n",
    "- **Risk Management Failure:** Value-at-Risk (VaR) based on normal distribution underestimates extreme losses\n",
    "\n",
    "**Real Numbers:**\n",
    "- Normal model: $P(Z > 5) \\approx 3 \\times 10^{-7}$ (1 in 3.5 million)\n",
    "- S&P 500 daily returns: 5-sigma moves occur about 1 in 14,000 days (observed reality)\n",
    "- This is 250 times more frequent than normal model predicts!\n",
    "\n",
    "**Alternatives:** Student-t distribution, Cauchy distribution, or mixture models for heavy tails.\n",
    "\n",
    "**3. Continuous and Unbounded Support**\n",
    "\n",
    "**Limitation:** Normal distribution assigns positive probability to all real numbers, including negative values.\n",
    "\n",
    "**Problems:**\n",
    "- **Non-negative Quantities:** Heights, weights, prices, counts cannot be negative\n",
    "- **Bounded Quantities:** Proportions, probabilities, percentages must be in [0,1] or [0,100]\n",
    "\n",
    "**Example:** Modeling human height with $\\mathcal{N}(170, 10^2)$ cm implies $P(\\text{height} < 0) > 0$, which is physically impossible.\n",
    "\n",
    "**When It Matters:** If $\\mu$ is many standard deviations away from the boundary, probability of violation is negligible.\n",
    "\n",
    "**Rule of Thumb:** Normal approximation is acceptable if $\\mu > 3\\sigma$ (for lower bound) or $\\mu < U - 3\\sigma$ (for upper bound $U$).\n",
    "\n",
    "**Alternatives:** \n",
    "- Log-normal for positive values\n",
    "- Truncated normal for bounded variables\n",
    "- Beta distribution for proportions in [0,1]\n",
    "\n",
    "**4. Independence Assumption in Multivariate Applications**\n",
    "\n",
    "**Limitation:** Multivariate normal assumes specific correlation structure. Real-world dependencies can be more complex.\n",
    "\n",
    "**Example:** In portfolio theory, assuming joint normal returns misses:\n",
    "- Correlation breakdown during crises (all assets become correlated)\n",
    "- Non-linear dependencies (copula effects)\n",
    "- Tail dependence (extreme events occur together)\n",
    "\n",
    "**Impact:** Diversification benefits are overestimated, portfolio risk is underestimated.\n",
    "\n",
    "**5. Central Limit Theorem Requirements**\n",
    "\n",
    "**Limitation:** The justification \"by CLT\" assumes:\n",
    "- Sum of many i.i.d. random variables\n",
    "- Finite variance\n",
    "- Sufficient sample size\n",
    "\n",
    "**Violations:**\n",
    "- **Small Sample Size:** With $n < 30$, CLT approximation may be poor, especially for skewed distributions\n",
    "- **Heavy-Tailed Components:** If individual variables have infinite variance (e.g., Cauchy), CLT does not apply\n",
    "- **Dependence:** Correlated observations slow down convergence to normality\n",
    "\n",
    "**Example:** Average of $n=10$ uniform random variables is NOT well-approximated by normal (noticeable deviation).\n",
    "\n",
    "**Guideline:** For skewed data, need $n \\geq 100$ for good normal approximation. For symmetric data, $n \\geq 30$ often suffices.\n",
    "\n",
    "**6. Parameter Estimation Uncertainty**\n",
    "\n",
    "**Limitation:** In practice, $\\mu$ and $\\sigma^2$ are estimated from data, introducing additional uncertainty.\n",
    "\n",
    "**Impact:**\n",
    "- Confidence intervals should use $t$-distribution, not normal, for small samples\n",
    "- Prediction intervals wider than nominal\n",
    "- Model risk: what if true distribution is not normal?\n",
    "\n",
    "**Example:** With $n=20$ samples, estimating $\\mu$ and $\\sigma$:\n",
    "- Using $Z$ distribution: 95% CI is $\\bar{X} \\pm 1.96 \\frac{s}{\\sqrt{n}}$\n",
    "- Using $t_{19}$ distribution: 95% CI is $\\bar{X} \\pm 2.09 \\frac{s}{\\sqrt{n}}$\n",
    "- The $t$ interval is 6.6% wider, properly accounting for estimation uncertainty\n",
    "\n",
    "**7. Computational and Interpretability Issues**\n",
    "\n",
    "**Limitation:** Normal CDF $\\Phi(x)$ has no closed form. Must use tables, approximations, or numerical integration.\n",
    "\n",
    "**Practical Implications:**\n",
    "- Need software or tables for exact calculations\n",
    "- Approximations (e.g., $\\Phi(x) \\approx 1 - \\frac{1}{2}e^{-2x^2/\\pi}$ for $x > 0$) introduce error\n",
    "- Not \"explainable\" to non-technical stakeholders\n",
    "\n",
    "**When It Matters:** High-stakes decisions (medical, financial) require exact probabilities, not approximations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
